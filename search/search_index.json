{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>Welcome to the documentation for the Miden compiler toolchain.</p> <p>Warning</p> <p>The compiler is currently in an experimental state, and has known bugs and limitations, it is not yet ready for production usage. However, we\u2019d encourage you to start experimenting with it yourself, and give us feedback on any issues or sharp edges you encounter.</p> <p>The documentation found here should provide a good starting point for the current capabilities of the toolchain, however if you find something that is not covered, but is not listed as unimplemented or a known limitation, please let us know by reporting an issue on the compiler issue tracker.</p>"},{"location":"#what-is-provided","title":"What is provided?","text":"<p>The compiler toolchain consists of the following primary components:</p> <ul> <li>An intermediate representation (IR), which can be lowered to by compiler backends wishing to support Miden as a target. The Miden IR is an SSA IR, much like Cranelift or LLVM, providing a much simpler path from any given source language (e.g. Rust), to Miden Assembly. It is used internally by the rest of the Miden compiler suite.</li> <li>A WebAssembly (Wasm) frontend for Miden IR. It can handle lowering both core Wasm modules, as well as basic components using the experimental WebAssembly Component Model. Currently, the Wasm frontend is known to work with Wasm modules produced by <code>rustc</code>, which is largely just what LLVM produces, but with the shadow stack placed at the start of linear memory rather than after read-only data. In the future we intend to support more variety in the structure of Wasm modules we accept, but for the time being we\u2019re primarily focused on using this as the path for lowering Rust to Miden.</li> <li>The compiler driver, in the form of the <code>midenc</code> executable, and a Rust crate, <code>midenc-compiler</code> to allow integrating the compiler into other tools. This plays the same role as <code>rustc</code> does in the Rust ecosystem.</li> <li>A Cargo extension, <code>cargo-miden</code>, that provides a convenient developer experience for creating and compiling Rust projects targeting Miden. It contains a project template for a basic Rust crate, and handles orchestrating <code>rustc</code> and <code>midenc</code> to compile the crate to WebAssembly, and then to Miden Assembly.</li> <li>A terminal-based interactive debugger, available via <code>midenc debug</code>, which provides a UI very similar to <code>lldb</code> or <code>gdb</code> when using the TUI mode. You can use this to run a program, or step through it cycle-by-cycle. You can set various types of breakpoints; see the source code, call stack, and contents of the operand stack at the current program point; as well as interatively read memory and format it in various ways for display.</li> <li>A Miden SDK for Rust, which provides types and bindings to functionality exported from the Miden standard library, as well as the Miden transaction kernel API. You can use this to access native Miden features which are not provided by Rust out-of-the-box. The project template generated by <code>cargo miden new</code> automatically adds this as a dependency.</li> </ul>"},{"location":"#what-can-i-do-with-it","title":"What can I do with it?","text":"<p>That all sounds great, but what can you do with the compiler today? The answer depends a bit on what aspect of the compiler you are interested in:</p>"},{"location":"#rust","title":"Rust","text":"<p>The most practically useful, and interesting capability provided by the compiler currently, is the ability to compile arbitrary Rust programs to Miden Assembly. See the guides for more information on setting up and compiling a Rust crate for execution via Miden.</p>"},{"location":"#webassembly","title":"WebAssembly","text":"<p>More generally, the compiler frontend is capable of compiling WebAssembly modules, with some constraints, to Miden Assembly. As a result, it is possible to compile a wider variety of languages to Miden Assembly than just Rust, so long as the language can compile to WebAssembly. However, we do not currently provide any of the language-level support for languages other than Rust, and have limited ability to provide engineering support for languages other than Rust at this time.</p> <p>Our Wasm frontend does not support all of the extensions to the WebAssembly MVP, most notably the reference types and GC proposals.</p>"},{"location":"#miden-ir","title":"Miden IR","text":"<p>If you are interested in compiling to Miden from your own compiler, you can target Miden IR, and invoke the driver from your compiler to emit Miden artifacts. At this point in time, we don\u2019t have the resources to provide much in the way of engineering support for this use case, but if you find issues in your efforts to use the IR in your compiler, we would certainly like to know about them!</p> <p>We do not currently perform any optimizations on the IR, since we are primarily working with the output of compiler backends which have already applied optimizations, at this time. This may change in the future, but for now it is expected that you implement your own optimization passes as needed.</p>"},{"location":"#known-bugs-and-limitations","title":"Known bugs and limitations","text":"<p>For the latest information on known bugs, see the issue tracker.</p> <p>See Known Limitations for details on what functionality is missing or only partially implemented.</p>"},{"location":"#where-to-start","title":"Where to start?","text":"<p>Provided here are a set of guides which are focused on documenting a couple of supported workflows we expect will meet the needs of most users, within the constraints of the current feature set of the compiler. If you find that there is something you wish to do that is not covered, and is not one of our known limitations, please open an issue, and we will try to address the missing docs as soon as possible.</p>"},{"location":"#installation","title":"Installation","text":"<p>To get started, there are a few ways you might use the Miden compiler. Select the one that applies to you, and the corresponding guide will walk you through getting up and running:</p> <ol> <li>Using the Cargo extension</li> <li>Using the <code>midenc</code> executable</li> </ol>"},{"location":"appendix/calling-conventions/","title":"Calling conventions","text":"<p>This document describes the various calling conventions recognized/handled by the compiler, including a specification for the interaction with the IR type system.</p> <p>There are four calling conventions represented in the compiler:</p> <ul> <li><code>C</code> aka <code>SystemV</code>, which corresponds to the C ABI commonly used for C foreign-function interfaces (FFI).   We specifically use the System V ABI because it is well understood, documented, and straightforward.</li> <li><code>Fast</code>, this convention allows the compiler to follow either the <code>C</code> calling convention, or modify it   as it sees fit on a function-by-function basis. This convention provides no guarantees about how a   callee will expect arguments to be passed, so should not be used for functions which are expected to   have a stable, predictable interface. This is a good choice for local functions, or functions which are   only used within an executable/library and are not part of the public interface.</li> <li><code>Kernel</code>, this is a special calling convention that is used when defining kernel modules in the IR.   Functions which are part of the kernel\u2019s public API are required to use this convention, and it is not   possible to call a function via <code>syscall</code> if the callee is not defined with this convention. Because of   the semantics of <code>syscall</code>, this convention is highly restrictive. In particular, it is not permitted to   pass pointer arguments, or aggregates containing pointers, as <code>syscall</code> involves a context switch, and   thus memory in the caller is not accessible to the callee, and vice versa.</li> <li><code>Contract</code>, this is a special calling convention that is used when defining smart contract functions, i.e.   functions that can be <code>call</code>\u2018d. The compiler will not permit you to <code>call</code> a function if the callee is not   defined with this convention, and functions with this convention cannot be called via <code>exec</code>. Like <code>syscall</code>,   the <code>call</code> instruction involves a context switch, however, unlike the <code>Kernel</code> convention, the <code>Contract</code>   convention is allowed to have types in its signature that are/contain pointers, with certain caveats around   those pointers.</li> </ul> <p>All four conventions above are based on the System V C ABI, tailored to the Miden VM. The only exception is <code>Fast</code>, which may modify the ABI arbitrarily as it sees fit, and makes no guarantees about what modifications, if any, it will make.</p>"},{"location":"appendix/calling-conventions/#data-representation","title":"Data representation","text":"<p>The following is a description of how the IR type system is represented in the <code>C</code> calling convention. Later, a description of how the other conventions extend/restrict/modify this representation will be provided.</p>"},{"location":"appendix/calling-conventions/#scalars","title":"Scalars","text":"General type C Type IR Type <code>sizeof</code> Alignment (bytes) Miden Type Integer <code>_Bool</code>/<code>bool</code> <code>I1</code> 1 1 u32 Integer <code>char</code>, <code>signed char</code> <code>I8</code> 1 1 i32<sup>1</sup> Integer <code>unsigned char</code> <code>U8</code> 1 1 u32 Integer <code>short</code> / <code>signed short</code> <code>I16</code> 2 2 i32<sup>1</sup> Integer <code>unsigned short</code> <code>U16</code> 2 2 u32 Integer <code>int</code> / <code>signed int</code> / <code>enum</code> <code>I32</code> 4 4 i32<sup>1</sup><sup>8</sup> Integer <code>unsigned int</code> <code>U32</code> 4 4 u32 Integer <code>long</code> / <code>signed long</code> <code>I32</code> 4 4 i32<sup>1</sup> Integer <code>unsigned long</code> / <code>size_t</code> <code>U32</code> 4 4 u32 Integer <code>long long</code> / <code>signed long long</code> <code>I64</code> 8 8 i64<sup>2</sup> Integer <code>unsigned long long</code> <code>U64</code> 8 8 u64<sup>3</sup> Pointer <code>any-type *</code> / <code>any-type (*)()</code> <code>Ptr(_)</code> 4 4 u32<sup>6</sup><sup>7</sup> Floating point <code>float</code> <code>F32</code> 4 4 u32<sup>4</sup> Floating point <code>double</code> <code>F64</code> 8 8 u64<sup>4</sup> Floating point <code>long double</code> 16 16 (none)<sup>5</sup> <p>Note</p> <p>The compiler does not support scalars larger than one word (128 bits) at this time. As a result, anything that is larger than that must be allocated in linear memory, or in an automatic allocation (function-local memory), and passed around by reference.</p> <p>The native scalar type for the Miden VM is a \u201cfield element\u201d, specifically a 64-bit value representing an integer in the \u201cGoldilocks\u201d field, i.e. <code>0..(2^64-2^32+1)</code>. A number of instructions in the VM operate on field elements directly. However, the native integral/pointer type, i.e. a \u201cmachine word\u201d, is actually <code>u32</code>. This is because a field element can fully represent 32-bit integers, but not the full 64-bit integer range. Values of <code>u32</code> type are valid field element values, and can be used anywhere that a field element is expected (barring other constraints).</p> <p>Miden also has the notion of a \u201cword\u201d, not to be confused with a \u201cmachine word\u201d (by which we mean the native integral type used to represent pointers), which corresponds to a set of 4 field elements. Words are commonly used in Miden, particularly to represent hashes, and a number of VM instructions operate on word-sized operands. As an aside, 128-bit integer values are represented using a word, or two 64-bit limbs (each limb consisting of two 32-bit limbs).</p> <p>All integral types mentioned above, barring field elements, use two\u2019s complement encoding. Unsigned integral types make use of the sign bit to change the value range (i.e. 0..2^32-1, rather than -2<sup>31..2</sup>31-1), but the encoding follows two\u2019s complement rules.</p> <p>The Miden VM only has native support for field elements, words, and <code>u32</code>; all other types are implemented in software using intrinsics.</p>"},{"location":"appendix/calling-conventions/#aggregates-and-unions","title":"Aggregates and unions","text":"<p>Structures and unions assume the alignment of their most strictly aligned component. Each member is assigned to the lowest available offset with the appropriate alignment. The size of any object is always a multiple of the object\u2019s alignment. An array uses the same alignment as its elements. Structure and union objects can require padding to meet size and alignment constraints. The contents of any padding is undefined.</p>"},{"location":"appendix/calling-conventions/#memory-model","title":"Memory model","text":"<p>Interacting with memory in Miden is quite similar to WebAssembly in some ways:</p> <ul> <li>The address space is linear, with addresses starting at zero, and ranging up to 2^32-1</li> <li>There is no memory protection per se, you either have full read/write access, or no access to a specific memory context</li> <li>How memory is used is completely up to the program being executed</li> </ul> <p>This is where it begins to differ though, and takes on qualities unique to Miden (in part, or whole):</p> <ul> <li>Certain regions of the address space are \u201creserved\u201d for special uses, improper use of those regions may result in undefined behavior.</li> <li>Miden has different types of function call instructions: <code>call</code> vs <code>syscall</code> vs <code>exec</code>. The first two perform a context switch when transferring control to the callee, and the callee has no access to the caller\u2019s memory (and the caller has no access to the callee\u2019s memory). As a result, references to memory cannot be passed from caller to callee in arguments, nor can they be returned from the callee to the caller.</li> <li>Most significant of all though, is that Miden does not have byte-addressable memory, it is instead word-addressable, i.e. every address refers to a full word.</li> <li>It is not possible to load a specific field element from a word in memory, unless it happens to be the first element of the word. Instead, one must load the full word, and drop the elements you don\u2019t need.</li> </ul> <p>This presents some complications, particularly:</p> <ul> <li>Most languages assume a byte-oriented memory model, which is not trivially mapped to a word-oriented model</li> <li>Simple things, such as taking the address of a field in a struct, and then dereferencing it, cannot be directly represented in Miden using native pointer arithmetic and <code>load</code> instruction. Operations like this must be translated into instruction sequences that load whole words from memory, extract the data needed, and discard the unused bits. This makes the choice of where in memory to store something much more important than byte-addressable memory, as loads of values which are not aligned to element or word boundaries can be quite inefficient in some cases.</li> </ul> <p>The compiler solves this by providing a byte-addressable IR, and internally translating operations in the IR to the equivalent sequence of Miden instructions needed to emulate that operation. This translation is done during code generation, and uses the following semantics to determine how a particular operation gets lowered:</p> <ul> <li>A byte-addressable pointer can be emulated in Miden\u2019s word-addressable environment using three pieces of information:</li> <li>The address of the word containing the first byte of the value, this is a \u201cnative\u201d Miden address value</li> <li>The index of the field element within that word containing the first byte of the value</li> <li>The offset (in bytes) from the start of the 4 byte chunk represented by the selected element, corresponding     to the first byte of the value. Since the chunk is represented as a u32 value, the offset is relative to the     most-significant bit (i.e. the byte with the lowest address is found in bits 55-63, since Miden integers are little-endian)</li> <li>This relies on us treating Miden\u2019s linear memory as an array of 16-byte chunks of raw memory (each word is 4 field elements, each element represents a 4-byte chunk). In short, much like translating a virtual memory address to a physical one, we must translate byte-addressable \u201cvirtual\u201d pointers to \u201creal\u201d Miden pointers with enough metadata to be able to extract the data we\u2019re trying to load (or encode the data we\u2019re trying to store).</li> </ul> <p>Because we\u2019re essentially emulating byte-addressable memory on word-addressable memory, loads/stores can range from simple and straightforward, to expensive and complicated, depending on the size and alignment of the value type. The process goes as follows:</p> <ul> <li>If the value type is word-aligned, it can be loaded/stored in as little as a single instruction depending on the size of the type</li> <li>Likewise if the value type is element-aligned, and the address is word-aligned</li> <li>Element-aligned values require some extra instructions to load a full word and drop the unused elements (or in the case of stores, loading the full word and replacing the element being stored)</li> <li>Loads/stores of types with sub-element alignment depend on the alignment of the pointer itself. Element or word-aligned addresses are still quite efficient to load/store from, but if the first byte of the value occurs in the middle of an element, then the bytes of that value must be shifted into place (or unused bytes masked out). If the value crosses an element boundary, then the bytes in both elements must be isolated and shifted into position such that they can be bitwise-OR\u2019d together to obtain the aligned value on the operand stack. If a value crosses a word boundary, then elements from both words must be loaded, irrelevant ones discarded, the relevant bytes isolated and shifted into position so that the resulting operand on the stack is aligned and laid out correctly.</li> <li>Stores are further complicated by the need to preserve memory that is not being explicitly written to, so values that do not overwrite a full word or element, require combining bytes from the operand being stored and what currently resides in memory.</li> </ul> <p>The worst case scenario for an unaligned load or store involves a word-sized type starting somewhere in the last element of the first word. This will require loading elements from three consecutive words, plus a lot of shuffling bits around to get the final, aligned word-sized value on the operand stack. Luckily, such operations should be quite rare, as by default all word-sized scalar types are word-aligned or element-aligned, so an unaligned load or store would require either a packed struct, or a type such as an array of bytes starting at some arbitrary address. In practice, most loads/stores are likely to be element-aligned, so most overhead from emulation will come from values which cross an element or word boundary.</p>"},{"location":"appendix/calling-conventions/#function-calls","title":"Function calls","text":"<p>This section describes the conventions followed when executing a function call via <code>exec</code>, including how arguments are passed on the operand stack, stack frames, etc. Later, we\u2019ll cover the differences when executing calls via <code>call</code> or <code>syscall</code>.</p>"},{"location":"appendix/calling-conventions/#locals-and-the-stack-frame","title":"Locals and the stack frame","text":"<p>Miden does not have registers in the style of hardware architectures. Instead it has an operand stack, on which an arbitrary number of operands may be stored, and local variables. In both cases - an operand on the operand stack, or a single local variable - the value type is nominally a field element, but it is easier to reason about them as untyped element-sized values. The operand stack is used for function arguments, return values, temporary variables, and scratch space. Local variables are not always used, but are typically used to hold multiply-used values which you don\u2019t want to keep on the operand stack, function-scoped automatic allocations (i.e. <code>alloca</code>), and other such uses.</p> <p>Miden does not have a stack frame per se. When you call a procedure in Miden Assembly, any local variables declared by that procedure are allocated space in a reserved region of linear memory in a single consecutive chunk. However, there is no stack or frame pointer, and because Miden is a Harvard architecture machine, there are no return addresses. Instead, languages (such as C) which have the concept of a stack frame with implications for the semantics of say, taking the address of a local variable, will need to emit code in function prologues and epilogues to maintain a shadow stack in Miden\u2019s linear memory. If all you need is local variables, you can get away with leaning on Miden\u2019s notion of local variables without implementing a shadow stack.</p> <p>Because there are no registers, the notion of callee-saved or caller-saved registers does not have a direct equivalent in Miden. However, in its place, a somewhat equivalent set of rules defines the contract between caller and callee in terms of the state of the operand stack, those are described below in the section covering the operand stack.</p>"},{"location":"appendix/calling-conventions/#the-shadow-stack","title":"The shadow stack","text":"<p>Miden is a Harvard architecture; as such, code and data are not in the same memory space. More precisely, in Miden, code is only addressable via the hash of the MAST root of that code, which must correspond to code that has been loaded into the VM. The hash of the MAST root of a function can be used to call that function both directly and indirectly, but that is the only action you can take with it. Code can not be generated and called on the fly, and it is not stored anywhere that is accessible to code that is currently executing.</p> <p>One consequence of this is that there are no return addresses or instruction pointers visible to executing code. The runtime call stack is managed by the VM itself, and is not exposed to executing code in any way. This means that address-taken local C variables need to be on a separate stack in linear memory (which we refer to as a \u201cshadow stack\u201d). Not all functions necessarily require a frame in the shadow stack, as it cannot be used to perform unwinding, so only functions which have locals require a frame.</p> <p>The Miden VM actually provides some built-in support for stack frames when using Miden Assembly. Procedures which are declared with some number of locals, will be automatically allocated sufficient space for those locals in a reserved region of linear memory when called. If you use the <code>locaddr</code> instruction to get the actual address of a local, that address can be passed as an argument to callees (within the constraints of the callee\u2019s calling convention).</p> <p>Languages with more elaborate requirements with regard to the stack will need to implement their own shadow stack, and emit code in function prologues/epilogues to manage it.</p>"},{"location":"appendix/calling-conventions/#the-operand-stack","title":"The operand stack","text":"<p>The Miden virtual machine is a stack machine, not a register machine. Rather than having a fixed set of registers that are used to store and manipulate scalar values, the Miden VM has the operand stack, which can hold an arbitrary number of operands (where each operand is a single field element), of which the first 16 can be directly manipulated using special stack instructions. The operand stack is, as the name implies, a last-in/first-out data structure.</p> <p>The following are basic rules all conventions are expected to follow with regard to the operand stack:</p> <ol> <li>The state of the operand stack from the point of view of the caller should be preserved, with two exceptions:</li> <li>The callee is expected to consume all of its arguments, and the caller will expect those operands to be gone when control is returned to it</li> <li>If the callee signature declares a return value, the caller expects to see that on top of the stack when control is returned to it</li> <li>No more than 16 elements of the operand stack may be used for passing arguments. If more than that is required to represent all of the arguments, then one of the following must happen:</li> <li>Spill to stack frame: in this scenario, up to 15 elements of the operand stack are used for arguments, and the remaining element is used to hold   a pointer to a local variable in the caller\u2019s stack frame. That local variable is a struct whose fields are the spilled arguments, appearing in   the same order as they would be passed. The callee must use the pointer it is given to compute the effective address for each spilled argument   that it wishes to access.</li> <li>Spill to heap: this is basically identical to the approach above, except the memory is allocated from the global heap, rather than using memory   associated with the caller\u2019s stack frame.</li> <li>Spill to the advice provider: in this scenario, 12 elements of the stack are used for arguments, and the remaining 4 are used to hold a hash   which refers to the remaining arguments on the advice provider stack. The callee must arrange to fetch the spilled arguments from the advice   provider using that hash.</li> </ol>"},{"location":"appendix/calling-conventions/#function-signatures","title":"Function signatures","text":"<p>Miden Abstract Syntax Trees (MASTs) do not have any notion of functions, and as such are not aware of parameters, return values, etc. For this document, that\u2019s not a useful level of abstraction to examine. Even a step higher, Miden Assembly (MASM) has functions (procedures in MASM parlance), but no function signature, i.e. given a MASM procedure, there is no way to know how many arguments it expects, how many values it returns, let alone the types of arguments/return values. Instead, we\u2019re going to specify calling conventions in terms of Miden IR, which has a fairly expressive type system more or less equivalent to that of LLVM, and how that translates to Miden primitives.</p> <p>Functions in Miden IR always have a signature, which specify the following:</p> <ul> <li>The calling convention required to call the function</li> <li>The number and types of the function arguments</li> <li>The type of value, if any, returned by the function, and whether it is returned by value or reference</li> </ul> <p>The following table relates IR types to how they are expected to be passed from the caller to the callee, and vice versa:</p> Type Parameter Result scalar direct direct empty struct or union<sup>1</sup> ignored ignored scalar struct or union<sup>2</sup> direct direct other struct or union indirect indirect array indirect N/A <p>The compiler will automatically generate code that follows these rules, but if emitting MASM from your own backend, it is necessary to do so manually. For example, a function whose signature specifies that it returns a non-scalar struct by value, must actually be written such that it expects to receive a pointer to memory allocated by the caller sufficient to hold the return value, as the first parameter of the function (i.e. the parameter is prepended to the parameter list). When returning, the function must write the return value to that pointer, rather than returning it on the operand stack. In this example, the return value is returned indirectly (by reference).</p> <p>A universal rule is that the arguments are passed in reverse order, i.e. the first argument in the parameter list of a function will be on top of the operand stack. This is different than many Miden instructions which seemingly use the opposite convention, e.g. <code>add</code>, which expects the right-hand operand on top of the stack, so <code>a + b</code> is represented like <code>push a, push b, add</code>. If we were to implement <code>add</code> as a function, it would instead be <code>push b, push a, exec.add</code>. The rationale behind this is that, in general, the more frequently used arguments appear earlier in the parameter list, and thus we want those closer to the top of the operand stack to reduce the amount of stack manipulation we need to do.</p> <p>Arguments/return values are laid out on the operand stack just like they would be as if you had just loaded it from memory, so all arguments are aligned, but may span multiple operands on the operand stack as necessary based on the size of the type (i.e. a struct type that contains a <code>u32</code> and a <code>i1</code> field would require two operands to represent). If the maximum number of operands allowed for the call is reached, any remaining arguments must be spilled to the caller\u2019s stack frame, or to the advice provider. The former is used in the case of <code>exec</code>/<code>dynexec</code>, while the latter is used for <code>call</code> and <code>syscall</code>, as caller memory is not accessible to the callee with those instructions.</p> <p>While ostensibly 16 elements is the maximum number of operands on the operand stack that can represent function arguments, due to the way <code>dynexec</code>/<code>dyncall</code> work, it is actually limited to 12 elements, because at least 4 must be free to hold the hash of the function being indirectly called.</p> <ol> <li> <p>Zero-sized types have no representation in memory, so they are ignored/skipped\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Any struct or union that recursively (including through nested structs, unions, and arrays) contains just a single scalar value and is not specified to have greater than natural alignment.\u00a0\u21a9\u21a9</p> </li> <li> <p>u64 is not a native Miden type, but is implemented in software using two 32-bit limbs (i.e. a pair of field elements)\u00a0\u21a9</p> </li> <li> <p>floating-point types are not currently supported, but will be implemented using compiler intrinsics\u00a0\u21a9\u21a9</p> </li> <li> <p><code>long double</code> values correspond to 128-bit IEEE-754 quad-precision binary128 values. These are not currently supported, and we have no plans to support them in the near term. Should we ever provide such support, we will do so using compiler intrinsics.\u00a0\u21a9</p> </li> <li> <p>A null pointer (for all types) always has the value zero.\u00a0\u21a9</p> </li> <li> <p>Miden\u2019s linear memory is word-addressable, not byte-addressable. The <code>Ptr</code> type has an <code>AddressSpace</code> parameter, that by default is set to the byte-addressable address space. The compiler translates values of <code>Ptr</code> type that are in this address space, into the Miden-native, word-addressable address space during codegen of load/store operations. See the section on the memory model below for more details.\u00a0\u21a9</p> </li> <li> <p>An <code>enum</code> is <code>i32</code> if all members of the enumeration can be represented by an <code>int</code>/<code>unsigned int</code>, otherwise it uses i64.\u00a0\u21a9</p> </li> </ol>"},{"location":"appendix/canonabi-adhocabi-mismatch/","title":"Canonical ABI vs Miden ABI incompatibility","text":"<p>This document describes an issue that arises when trying to map the ad-hoc calling convention/ABI used by various Miden Assembly procedures, such as those comprising the transaction kernel, and the \u201ccanonical\u201d ABI(s) representable in Rust. It proposes a solution to this problem in the form of adapter functions, where the details of a given adapter are one of a closed set of known ABI transformation strategies.</p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#summary","title":"Summary","text":"<p>The gist of the problem is that in Miden, the size and number of procedure results is only constrained by the maximum addressable operand stack depth. In most programming languages, particularly those in which interop is typically performed using some variant of the C ABI (commonly the one described in the System V specification), the number of results is almost always limited to a single result, and the size of the result type is almost always limited to the size of a single machine word, in some cases two. On these platforms, procedure results of greater arity or size are typically handled by reserving space in the caller\u2019s stack frame, and implicitly prepending the parameter list of the callee with an extra parameter: a pointer to the memory allocated for the return value. The callee will directly write the return value via this pointer, instead of returning a value in a register.</p> <p>In the case of Rust, this means that attempting to represent a procedure that returns multiple values, or returns a larger-than-machine-word type, such as <code>Word</code>, will trigger the implicit transformation described above, as this is allowed by the standard Rust calling conventions. Since various Miden procedures that are part of the standard library and the transaction kernel are affected by this, the question becomes \u201chow do we define bindings for these procedures in Rust?\u201d.</p> <p>The solution is to have the compiler emit glue code that closes the gap between the two ABIs. It does so by generating adapter functions, which wrap functions that have an ABI unrepresentable in Rust, and orchestrate lifting/lowering arguments and results between the adapter and the \u201creal\u201d function.</p> <p>When type signatures are available for all Miden Assembly procedures, we can completely automate this process. For now, we will require a manually curated list of known procedures, their signatures, and the strategy used to \u201cadapt\u201d those procedures for binding in Rust.</p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#background","title":"Background","text":"<p>After analyzing all of the functions in the transaction kernel API, the most common cause of a mismatch between Miden and Rust ABIs, is due to implicit \u201csret\u201d parameters, i.e. the transformation mentioned above which inserts an implicit pointer to the caller\u2019s stack frame for the callee to write the return value to, rather than doing so in a register (or in our case, on the operand stack). This seems to happen for any type that is larger than 8 bytes (i64).</p> <p>Tip</p> <p>For a complete list of the transaction kernel functions, in WIT format, see miden.wit.</p> <p>For most transaction kernel functions, the adapter function can be generated automatically using the pattern recognition and adapter functions described below.</p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#prerequisites","title":"Prerequisites","text":"<ul> <li>The compiler must know the type signature for any function we wish to apply the adapter strategy to</li> </ul>"},{"location":"appendix/canonabi-adhocabi-mismatch/#implementation","title":"Implementation","text":"<p>The compiler will analyze every component import to determine if that import requires an adapter, as determined by matching against a predefined set of patterns. The adapter generation will take place in the frontend, as it has access to all of the needed information, and ensures that we do not have any transformations or analyses that make decisions on the un-adapted procedure.</p> <p>The following pseudo-code can be used to recognize the various Miden ABI patterns:</p> <pre><code>pub enum MidenAbiPattern {\n    /// Calling this procedure will require an sret parameter on the Rust side, so\n    /// we need to emit an adapter that will lift/lower calls according to that\n    /// strategy.\n    ReturnViaPointer,\n    /// The underlying procedure is fully representable in Rust, and requires no adaptation.\n    NoAdapterNeeded,\n}\n\npub struct MidenAbiPatternRecognition {\n    pattern: Option&lt;MidenAbiPattern&gt;,\n    component_function: ComponentFunctionType,\n    wasm_core_func: Signature,\n    tx_kernel_function: Signature,\n}\n\npub fn recognize_miden_abi_pattern(\n    component_function: &amp;ComponentFunctionType,\n    wasm_core_func: &amp;Signature,\n    tx_kernel_func: &amp;Signature) -&gt; MidenAbiPatternRecognition {\n    if wasm_core_func == tx_kernel_func {\n        return MidenAbiPatternRecognition {\n            pattern: Some(NoAdapterNeeded),\n            component_function,\n            wasm_core_function,\n            tx_kernel_function,\n        };\n    } else if component_function.returns[0].byte_size &gt; 8 &amp;&amp; wasm_core_func.params.last() == I32 {\n        return MidenAbiPatternRecognition {\n            pattern: Some(ReturnViaPointer),\n            component_function,\n            wasm_core_function,\n            tx_kernel_function,\n        };\n    } else {\n        return MidenAbiPatternRecognition {\n            pattern: None,\n            component_function,\n            wasm_core_function,\n            tx_kernel_function,\n        };\n    }\n}\n</code></pre> <p>The following pseudo-code can then be used to generate the adapter function:</p> <pre><code>pub fn generate_adapter(recognition: MidenAbiPatternRecognition) {\n    match recognition.pattern {\n        Some(pattern) =&gt; generate_adapter(\n            pattern,\n            recognition.component_function,\n            recognition.wasm_core_function,\n            recognition.tx_kernel_function\n        ),\n        None =&gt; use_manual_adapter(\n            recognition.component_function,\n            recognition.wasm_core_function,\n            recognition.tx_kernel_function\n        ),\n    }\n}\n\n/// Escape hatch for the cases when the compiler can't generate an adapter function automatically\n/// and we need to provide the adapter function manually.\npub fn use_manual_adapter(...) {\n    // Find and use the manual adapter in the adapter library for the tx_kernel_function\n}\n</code></pre> <p>The manual adapter library is a collection of adapter functions that are used when the compiler can\u2019t generate an adapter function automatically so its expected to be provided. The manual adapter library is a part of the Miden compiler. It is not anticipated that we will have many, or any, of these; however in the near term we are going to manually map procedures to their adapter strategies, as we have not yet automated the pattern recognition step.</p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#return-via-pointer-adapter","title":"Return-via-pointer adapter","text":"<p>The return value is expected to be returned by storing its flattened representation in a pointer passed as an argument.</p> <p>Recognize this Miden ABI pattern by looking at the Wasm component function type. If the return value is bigger than 64 bits, expect the last argument in the Wasm core(HIR) signature to be <code>i32</code> (a pointer).</p> <p>The adapter function calls the tx kernel function and stores the result in the provided pointer (the last argument of the Wasm core function).</p> <p>Here is the pseudo-code for generating the adapter function for the return-via-pointer Miden ABI pattern:</p> <pre><code>let ptr = wasm_core_function.params.last();\nlet adapter_function = FunctionBuilder::new(wasm_core_function.clone());\nlet tx_kernel_function_params = wasm_core_function.params.drop_last();\nlet tx_kernel_func_val = adapter_function.call(tx_kernel_function, tx_kernel_function_params);\nadapter_function.store(tx_kernel_func_val, ptr);\nadapter_function.build();\n</code></pre> <p>Here is how the adapter might look like in a pseudo-code for the <code>add_asset</code> function:</p> <pre><code>/// Takes an Asset as an argument and returns a new Asset\nfunc wasm_core_add_asset(v0: f64, v1: f64, v2: f64, v3: f64, ptr: i32) {\n    v4 = call tx_kernel_add_asset(v0, v1, v2, v3);\n    // v4 is a tuple of 4 f64 values\n    store v4 in ptr;\n}\n</code></pre>"},{"location":"appendix/canonabi-adhocabi-mismatch/#no-op-adapter","title":"No-op adapter","text":"<p>No adapter is needed. The Wasm core function type is the same as the tx kernel ad-hoc signature.</p> <p>This Miden ABI pattern is selected if no other Miden ABI pattern is applicable and the wasm core function signature is the same as the tx kernel ad-hoc signature.</p> <p>For example, the <code>get_id</code> function falls under this Miden ABI pattern and its calls will be translated to the tx kernel function calls without any modifications.</p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#transaction-kernel-functions-that-require-manual-adapter-functions","title":"Transaction kernel functions that require manual adapter functions","text":""},{"location":"appendix/canonabi-adhocabi-mismatch/#get_assets","title":"<code>get_assets</code>","text":"<p><code>get_assets:func() -&gt; list&lt;core-asset&gt;</code> in the <code>note</code> interface is the only function that requires attention. In Canonical ABI, any function that returns a dynamic list of items needs to allocate memory in the caller\u2019s module due to the shared-nothing nature of the Wasm component model. For this case, a <code>realloc</code> function is passed as a part of lift/lower Canonical ABI options for the caller to allocate memory in the caller\u2019s module.</p> <p>Here are the signatures of the <code>get_assets</code> function in the WIT, core Wasm, and the tx kernel ad-hoc ABI: Comment from the <code>miden-base</code></p> <pre><code>#! Writes the assets of the currently executing note into memory starting at the specified address.\n#!\n#! Inputs: [dest_ptr]\n#! Outputs: [num_assets, dest_ptr]\n#!\n#! - dest_ptr is the memory address to write the assets.\n#! - num_assets is the number of assets in the currently executing note.\n</code></pre> <p>Wasm component function type: <code>get-assets: func() -&gt; list&lt;core-asset&gt;;</code></p> <p>Wasm core signature: <code>wasm_core_get_assets(i32) -&gt; ()</code></p> <p>If we add a new <code>get_assets_count: func() -&gt; u32;</code> function to the tx kernel and add the assets count parameter to the <code>get_assets</code> function (<code>get_assets: func(assets_count: u32) -&gt; list&lt;core-asset&gt;;</code>) we should have everything we need to manually write the adapter function for the <code>get_assets</code> function.</p> <p>The list is expected to be returned by storing the pointer to its first item in a <code>ptr</code> pointer passed as an argument and item count at <code>ptr + 4 bytes</code> address (<code>ptr</code> points to two pointers).</p> <p>We could try to recognize this Miden ABI pattern by looking at the Wasm component function type. If the return value is a list, expect the last argument in the Wasm core(HIR) signature to be <code>i32</code> (a pointer). The problem is recognizing the list count parameter in the Wasm core(HIR) signature.</p> <p>The adapter function calls allocates <code>asset_count * item_size</code> memory via the <code>realloc</code> call and passes the pointer to the newly allocated memory to the tx kernel function.</p> <p>Here is how the adapter function might look like in a pseudo-code for the <code>get_assets</code> function:</p> <pre><code>func wasm_core_get_assets(asset_count: u32, ptr_ptr: i32) {\n    mem_size = asset_count * item_size;\n    ptr = realloc(mem_size);\n    (actual_asset_count, ptr) = call tx_kernel_get_assets(ptr);\n    assert(actual_asset_count == asset_count);\n    store ptr in ptr_ptr;\n    store account_count in ptr_ptr + 4;\n}\n</code></pre> <p>Note</p> <p>Since the <code>get_assets</code> tx kernel function in the current form can trash the provided memory if the actual assets count differs from the returned by <code>get_assets_count</code>, we can introduce the asset count parameter to the <code>get_assets</code> tx kernel function and check that it the same as the actual assets count written to memory.</p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#the-example-of-some-functions-signatures","title":"The example of some functions signatures","text":""},{"location":"appendix/canonabi-adhocabi-mismatch/#add_asset-return-via-pointer-miden-abi-pattern","title":"<code>add_asset</code> (return-via-pointer Miden ABI pattern)","text":"<p>Comment from the <code>miden-base</code></p> <pre><code>#! Add the specified asset to the vault.\n#!\n#! Panics:\n#! - If the asset is not valid.\n#! - If the total value of two fungible assets is greater than or equal to 2^63.\n#! - If the vault already contains the same non-fungible asset.\n#!\n#! Stack: [ASSET]\n#! Output: [ASSET']\n#!\n#! - ASSET' final asset in the account vault is defined as follows:\n#!   - If ASSET is a non-fungible asset, then ASSET' is the same as ASSET.\n#!   - If ASSET is a fungible asset, then ASSET' is the total fungible asset in the account vault\n#!     after ASSET was added to it.\n</code></pre> <p>Wasm component function type: <code>add-asset(core-asset) -&gt; core-asset</code></p> <p>Wasm core signature: <code>wasm_core_add_asset(f64, f64, f64, f64, i32) -&gt; ()</code> The last <code>i32</code> is a pointer to a returned value (<code>word</code>)</p> <p>Tx kernel ad-hoc signature: <code>tx_kernel_add_asset(felt, felt, felt, felt) -&gt; (felt, felt, felt, felt)</code></p>"},{"location":"appendix/canonabi-adhocabi-mismatch/#get_id-no-adapter-needed-miden-abi-pattern","title":"<code>get_id</code> (no-adapter-needed Miden ABI pattern)","text":"<p>Comment from the <code>miden-base</code> <pre><code>#! Returns the account id.\n#!\n#! Stack: []\n#! Output: [acct_id]\n#!\n#! - acct_id is the account id.\n</code></pre></p> <p>Wasm component function type: <code>get-id() -&gt; account-id</code></p> <p>Wasm core signature: <code>wasm_core_get_id() -&gt; f64</code></p> <p>Tx kernel ad-hoc signature: <code>tx_kernel_get_id() -&gt; felt</code></p>"},{"location":"appendix/known-limitations/","title":"Known limitations","text":"<p>Tip</p> <p>See the issue tracker for information on known bugs. This document focuses on missing/incomplete features, rather than bugs.</p> <p>The compiler is still in its early stages of development, so there are various features that are unimplemented, or only partially implemented, and the test suite is still limited in scope, so we are still finding bugs on a regular basis. We are rapidly improving this situation, but it is important to be aware of this when using the compiler.</p> <p>The features discussed below are broken up into sections, to make them easier to navigate and reference.</p>"},{"location":"appendix/known-limitations/#rust-language-support","title":"Rust language support","text":""},{"location":"appendix/known-limitations/#floating-point-types","title":"Floating point types","text":"<ul> <li>Status: Unsupported</li> <li>Tracking Issue: N/A</li> <li>Release Milestone: N/A</li> </ul> <p>In order to represent <code>Felt</code> \u201cnatively\u201d in Rust, we were forced to piggy-back on the <code>f32</code> type, which is propagated through to WebAssembly, and allows us to handle those values specially.</p> <p>As a result, floating-point types in Rust are not supported at all. Any attempt to use them will result in a compilation error. We considered this a fair design tradeoff, as floating point math is unused/rare in the context in which Miden is used, in comparison to fixed-point or field arithmetic. In addition, implementing floating-point operations in software on the Miden VM would be extraordinarily expensive, which generally works against the purpose for using floats in the first place.</p> <p>At this point in time, we have no plans to support floats, but this may change if we are able to find a better/more natural representation for <code>Felt</code> in WebAssembly.</p>"},{"location":"appendix/known-limitations/#function-call-indirection","title":"Function call indirection","text":"<ul> <li>Status: Unimplemented</li> <li>Tracking Issue: #32</li> <li>Release Milestone: Beta 1</li> </ul> <p>This feature corresponds to <code>call_indirect</code> in WebAssembly, and is associated with Rust features such as trait objects (which use indirection to call trait methods), and closures. Note that the Rust compiler is able to erase the indirection associated with certain abstractions statically in some cases, shown below. If Rust is unable to statically resolve all call targets, then <code>midenc</code> will raise an error when it encounters any use of <code>call_indirect</code>.</p> <p>Warning</p> <p>The following examples rely on <code>rustc</code>/LLVM inlining enough code to be able to convert indirect calls to direct calls. This may require you to enable link-time optimization with <code>lto = \"fat\"</code> and compile all of the code in the crate together with <code>codegen-units = 1</code>, in order to maximize the amount of inlining that can occur. Even then, it may not be possible to remove some forms of indirection, in which case you will need to find another workaround.</p>"},{"location":"appendix/known-limitations/#iterator-lowered-to-loop","title":"Iterator lowered to loop","text":"<pre><code>pub fn is_zeroed(bytes: &amp;[u8; 32]) -&gt; bool {\n    // Rust is able to convert this to a loop, erasing the closure completely\n    bytes.iter().copied().all(|b| b == 0)\n}\n</code></pre>"},{"location":"appendix/known-limitations/#monomorphization-inlining","title":"Monomorphization + inlining","text":"<pre><code>pub fn call&lt;F, T&gt;(fun: F) -&gt; T\nwhere\n    F: Fn() -&gt; T,\n{\n    fun()\n}\n\n#[inline(never)]\npub fn foo() -&gt; bool { true }\n\nfn main() {\n    // Rust is able to inline the body of `call` after monomorphization, which results in\n    // the call to `foo` being resolved statically.\n    call(foo)\n}\n</code></pre>"},{"location":"appendix/known-limitations/#inlined-trait-impl","title":"Inlined trait impl","text":"<pre><code>pub trait Foo {\n    fn is_foo(&amp;self) -&gt; bool;\n}\n\nimpl Foo for u32 {\n    #[inline(never)]\n    fn is_foo(&amp;self) -&gt; bool { true }\n}\n\nfn has_foo(items: &amp;[dyn Foo]) -&gt; bool {\n    items.iter().any(|item| item.is_foo())\n}\n\nfn main() -&gt; u32 {\n    // Rust inlines `has_foo`, converts the iterator chain to a loop, and is able to realize\n    // that the `dyn Foo` items are actually `u32`, and resolves the call to `is_foo` to\n    // `&lt;u32 as Foo&gt;::is_foo`.\n    let foo: &amp;dyn Foo = &amp;u32::MAX as &amp;dyn Foo;\n    has_foo(&amp;[foo]) as u32\n}\n</code></pre>"},{"location":"appendix/known-limitations/#miden-sdk","title":"Miden SDK","text":"<ul> <li>Status: Incomplete</li> <li>Tracking Issue: #159 and #158</li> <li>Release Milestone: Beta 1</li> </ul> <p>The Miden SDK for Rust, is a Rust crate that provides the implementation of native Miden types, as well as bindings to the Miden standard library and transaction kernel APIs.</p> <p>Currently, only a very limited subset of the API surface has had bindings implemented. This means that there is a fair amount of native Miden functionality that is not yet available from Rust. We will be expanding the SDK rapidly over the next few weeks and months, but for the time being, if you encounter a missing API that you need, let us know, so we can ensure it is prioritized above APIs which are lesser used.</p>"},{"location":"appendix/known-limitations/#rustmiden-ffi-foreign-function-interface-and-interop","title":"Rust/Miden FFI (foreign function interface) and interop","text":"<ul> <li>Status: Internal Use Only</li> <li>Tracking Issue: #304</li> <li>Release Milestone: TBD</li> </ul> <p>While the compiler has functionality to link against native Miden Assembly libraries, binding against procedures exported from those libraries from Rust can require glue code to be emitted by the compiler in some cases, and the set of procedures for which this is done is currently restricted to a hardcoded whitelist of known Miden procedures.</p> <p>This affects any procedure which returns a type larger than <code>u32</code> (excluding <code>Felt</code>, which for this purpose has the same size). For example, returing a Miden <code>Word</code> from a procedure, a common return type, is not compatible with Rust\u2019s ABI - it will attempt to generate code which allocates stack space in the caller, which it expects the callee to write to, inserting a new parameter at the start of the parameter list, and expecting nothing to be returned by value. The compiler handles situations like these using a set of ABI \u201ctransformation strategies\u201d, which lift/lower differences between the Rust and Miden ABIs at call boundaries.</p> <p>To expose the FFI machinery for use with any Miden procedure, we need type signatures for those procedures at a minimum, and in some cases we may require details of the calling convention/ABI. This metadata does not currently exist, but is on the roadmap for inclusion into Miden Assembly and Miden packaging. Once present, we can open up the FFI for general use.</p>"},{"location":"appendix/known-limitations/#core-miden-functionality","title":"Core Miden functionality","text":""},{"location":"appendix/known-limitations/#dynamic-procedure-invocation","title":"Dynamic procedure invocation","text":"<ul> <li>Status: Unimplemented</li> <li>Tracking Issue: #32</li> <li>Release Milestone: Beta 1</li> </ul> <p>This is a dependency of Function Call Indirection described above, and is the mechanism by which we can perform indirect calls in Miden. In order to implement support for indirect calls in the Wasm frontend, we need underlying support for <code>dynexec</code>, which is not yet implemented.</p> <p>This feature adds support for lowering indirect calls to <code>dynexec</code> or <code>dyncall</code> instructions, depending on the ABI of the callee. <code>dyncall</code> has an additional dependency on support for Cross-Context Procedure Invocation.</p> <p>A known issue with this feature is that <code>dyn(exec|call)</code> consumes a word on the operand stack for the hash of the callee being invoked, but this word remains on the stack when entering the callee, which has the effect of requiring procedures to have a different ABI depending on whether they expect to be dynamically-invoked or not.</p> <p>Our solution to that issue is to generate stubs which are used as the target of <code>dyn(exec|call)</code>, the body of which drop the callee hash, fix up the operand stack as necessary, and then uses a simple <code>exec</code> or <code>call</code> to invoke the \u201creal\u201d callee. We will emit a single stub for every function which has its \u201caddress\u201d taken, and use the hash of the stub in place of the actual callee hash.</p>"},{"location":"appendix/known-limitations/#cross-context-procedure-invocation","title":"Cross-context procedure invocation","text":"<ul> <li>Status: Unimplemented</li> <li>Tracking Issue: #303</li> <li>Release Milestone: Beta 2</li> </ul> <p>This is required in order to support representing Miden accounts and note scripts in Rust, and compilation to Miden Assembly.</p> <p>Currently, you can write code in Rust that is very close to how accounts and note scripts will look like in the language, but it is not possible to actually implement either of those in Rust today. The reasons for this are covered in depth in the tracking issue linked above, but to briefly summarize, the primary issue has to do with the fact that Rust programs are compiled for a \u201cshared-everything\u201d environment, i.e. you can pass references to memory from caller to callee, write to caller memory from the callee, etc. In Miden however, contexts are \u201cshared-nothing\u201d units of isolation, and thus cross-context operations, such as performing a <code>call</code> from a note script to a method on an account, are not compatible with the usual calling conventions used by Rust and LLVM.</p> <p>The solution to this relies on compiling the Rust code for the <code>wasm32-wasip2</code> target, which emits a new kind of WebAssembly module, known as a component. These components adhere to the rules of the WebAssembly Component Model. Of primary interest to us, is the fact that components in this model are \u201cshared-nothing\u201d, and the ABI used to communicate across component boundaries, is specially designed to enforce shared-nothing  semantics on caller and callee. In addition to compiling for a specific Wasm target, we also rely on some additional tooling for describing component interfaces, types, and to generate Rust bindings for those descriptions, to ensure that calls across the boundary remain opaque, even to the linker, which ensures that the assumptions of the caller and callee with regard to what address space they operate in are preserved (i.e. a callee can never be inlined into the caller, and thus end up executing in the caller\u2019s context rather than the expected callee context).</p> <p>This is one of our top priorities, as it is critical to being able to use Rust to compile code for the Miden rollup, but it is also the most complex feature on our roadmap, hence why it is scheduled for our Beta 2 milestone, rather than Beta 1 (the next release), as it depends on multiple other subfeatures being implemented first.</p>"},{"location":"appendix/known-limitations/#packaging","title":"Packaging","text":""},{"location":"appendix/known-limitations/#package-format","title":"Package format","text":"<ul> <li>Status: Experimental</li> <li>Tracking Issue: #121</li> <li>Release Milestone: Beta 1</li> </ul> <p>This feature represents the ability to compile and distribute a single artifact that contains the compiled MAST, and all required and optional metadata to make linking against, and executing packages as convenient as a dynamic library or executable.</p> <p>The compiler currently produces, by default, an experimental implementation of a package format that meets the minimum requirements to support libraries and programs compiled from Rust:</p> <ul> <li>Name and semantic version information</li> <li>Content digest</li> <li>The compiled MAST and metadata about the procedures exported from it</li> <li>Read-only data segments and their hashes (if needed by the program, used to load data into the advice provider when a program is loaded, and to write those segments into linear memory when the program starts)</li> <li>Dependency information (optional, specifies what libraries were linked against during compilation)</li> <li>Debug information (optional)</li> </ul> <p>However, this package format is not yet understood by the Miden VM itself. This means you cannot, currently, compile a package and then run it using <code>miden run</code> directly. Instead, you can use <code>midenc run</code> to load and run code from a package, as the compiler ships with the VM embedded for use with the interactive debugger, and provides native support for packaging on top of it. You can also use <code>midenc debug</code> to execute your program interactively in the debugger, depending on your needs. See Debugging Programs for more information on how to use the debugger, and <code>midenc help run</code> for more information on executing programs with the <code>midenc run</code> command.</p> <p>While it is possible to emit raw MAST from <code>midenc</code>, rather than the experimental package format, the resulting artifact cannot be run without some fragile and error-prone manual setup, in order to ensure that the advice provider is correctly initialized with any read-only data segments. For now, it is recommended that you use the <code>midenc</code> tooling for testing programs, until the format is stabilized.</p>"},{"location":"design/frontends/","title":"Supported front ends","text":""},{"location":"design/frontends/#webassembly-wasm","title":"WebAssembly (Wasm)","text":"<p>TODO</p> <p>For the list of the unsupported Wasm core types, instructions and features, see the README.</p>"},{"location":"design/ir/","title":"High-Level Intermediate Representation (HIR)","text":"<p>This document describes the concepts, usage, and overall structure of the intermediate representation used by <code>midenc</code>.</p>"},{"location":"design/ir/#introduction","title":"Introduction","text":"<p>TODO</p>"},{"location":"design/ir/#concepts","title":"Concepts","text":""},{"location":"design/ir/#components","title":"Components","text":"<p>A component is a named entity that encapsulates one or more interfaces, and comes in two forms:</p> <ul> <li>An executable component, which has a statically-defined entrypoint, a function which initializes and executes a program encapsulated by the component.</li> <li>A library component, which exports one or more interfaces, and can be used as a dependency of other components.</li> </ul> <p>We also commonly refer to executable components as programs, and library components as libraries, which also correspond to the equivalent concepts in Miden Assembly. However, components are a more general abstraction over programs and libraries, where the distinction is mostly one of intended use and/or convention.</p> <p>Components can have zero or more dependencies, which are expressed in the form of interfaces that they require instances of at runtime. Thus any component that provides the interface can be used to satisfy the dependency.</p> <p>A component instance refers to a component that has had all of its dependencies resolved concretely, and is thus fully-defined.</p> <p>A component definition specifies four things:</p> <ol> <li>The name of the component</li> <li>The interfaces it imports</li> <li>The interfaces it exports</li> <li>The modules which implement the exported interfaces concretely</li> </ol>"},{"location":"design/ir/#interfaces","title":"Interfaces","text":"<p>An interface is a named entity that describes one or more functions that it exports. Conceptually, an interface loosely corresponds to the notion of a module, in that both a module and an interface define a namespace, in which one or more functions are exported.</p> <p>However, an interface, unlike a module, is abstract, and does not have any internal structure. It is more like a trait, in that it abstractly represents a set of named behaviors implemented by some component.</p>"},{"location":"design/ir/#modules","title":"Modules","text":"<p>A module is primarily two things:</p> <ol> <li>A container for one or more functions belonging to a common namespace</li> <li>A concrete implementation of one or more interfaces</li> </ol> <p>Functions within a module may be exported, and so a module always has an implicit interface consisting of all of its exported functions. Functions which are not exported, are only visible within the module, and do not form a part of the implicit interface of a module.</p> <p>Module names are used to name the implicit interface of the module. Thus, within a component, both imported interfaces, and the implicit interfaces of all modules it defines, can be used to resolve function references in those modules.</p> <p>A module defines a symbol table, whose entries are the functions defined in that module.</p>"},{"location":"design/ir/#functions","title":"Functions","text":"<p>A function is a special type of operation. It is special in the following ways:</p> <ul> <li>A function has a symbol, and thus declares an entry in the nearest containing symbol table.</li> <li>A function is isolated from above, i.e. the contents of the function cannot escape the function, nor reference things outside the function, except via symbol table references. Thus entities such as values and blocks are function-scoped, if not more narrowly scoped, in the case of operations with nested regions.</li> </ul> <p>A function has an arbitrary set of parameters and results, corresponding to its type signature. A function also has the notion of an application binary interface (ABI), which drives how code is generated for both caller and callee. For example, a function may have a specific calling convention as a whole, and specific parameters/results may have type-specific  semantics declared, such as whether to zero- or sign-extend the value if the input is of a smaller range.</p> <p>A function always consists of a single region, called the body, with at least one block, which is called the entry block. The block parameters of the entry block always correspond to the function parameters, i.e. the arity and type of the block parameters must match the function signature.</p> <p>Additionally, a function has an additional constraint on its body, which is that all blocks in the region must end with one of a restricted set of terminator operations: any branch operation, which transfers control between blocks of the region; the <code>unreachable</code> operation, which will result in aborting the program if executed; or the <code>return</code> operation, which must return the same arity and type of values declared in the function signature.</p>"},{"location":"design/ir/#global-variables","title":"Global Variables","text":"<p>A global variable is a second special type of operation, after functions:</p> <ul> <li>A global variable has a symbol, and declares an entry in the nearest containing symbol table.</li> <li>The initializer of a global variable is, like function bodies, isolated from above.</li> </ul> <p>A global variable may have an initializer, a single region/single block body which is implicitly executed to initialize the value of the global variable. The initializer must be statically evaluatable, i.e. a \u201cconstant\u201d expression. In most cases, this will simply be a constant value, but some limited forms of constant expressions are permitted.</p>"},{"location":"design/ir/#symbols-and-symbol-tables","title":"Symbols and Symbol Tables","text":"<p>A symbol is simply a named entity, e.g. a function <code>foo</code> is a symbol whose value is <code>foo</code>. On their own, symbols aren\u2019t particularly useful. This is where the concept of a symbol table becomes important.</p> <p>A symbol table is a collection of uniqued symbols belonging to the same namespace, i.e. every symbol has a single entry in the symbol table, regardless of entity type. Thus, it is not permitted to have both a function and a global variable with the same name, in the same symbol table. If such a thing needed to be allowed, perhaps because the namespace for functions and global variables are separate, then you would use a per-entity symbol table.</p> <p>For our purposes, a module defines a symbol table, and both functions and global variables share that table. We do not currently use symbol tables for anything else.</p>"},{"location":"design/ir/#operations","title":"Operations","text":"<p>An operation is the most important entity in HIR, and the most abstract. In the Regionalized Value State Dependence Graph paper, the entire representation described there consists of various types of operations. In HIR, we do not go quite that abstract, however we do take a fair amount of inspiration from that paper, as well as from MLIR.</p> <p>Operations consist of the following pieces:</p> <ul> <li>Zero or more regions and their constituent blocks</li> <li>Zero or more operands, i.e. arguments or inputs</li> <li>Zero or more results, or outputs, one of the two ways that values can be introduced</li> <li>Zero or more successors, in the case of operations which transfer control to another block in the same region.</li> <li>Zero or more attributes, the semantics of which depend on the operation.</li> <li>Zero or more traits, implemented by the operation.</li> </ul> <p>An operation always belongs to a block when in use.</p> <p>As you can see, this is a highly flexible concept. It is capable of representing modules and functions, as well as primitive instructions. It can represent both structured and unstructured control-flow. There is very little in terms of an IR that can\u2019t be represented using operations.</p> <p>However, in our case, we use operations for five specific concepts:</p> <ul> <li>Functions (the first of two special ops)</li> <li>Global Variables (the second of two special ops)</li> <li>Structured Control Flow (if/then, do/while and for loops)</li> <li>Unstructured Control Flow (br, cond_br, switch, ret)</li> <li>Primitive Instructions (i.e. things which correspond to the target ISA, e.g. <code>add</code>, <code>call</code>, etc.)</li> </ul> <p>For the most part, the fact that functions and global variables are implemented using operations is not particularly important. Instead, most operations you will interact with are of the other three varieties. While we\u2019ve broken them up into three categories, for the most part, they aren\u2019t actually significantly different. The primary difference is that the unstructured control-flow ops are valid terminators for blocks, in multi-block regions, while the structured control-flow ops are not, and only a few special cases of primitive ops are also valid terminators (namely the <code>ret</code> and <code>unreachable</code> ops). For most primitive and structured control-flow ops, their behavior appears very similar: they take some operands, perform some action, and possibly return some results.</p>"},{"location":"design/ir/#regions","title":"Regions","text":"<p>A region encapsulates a control-flow graph (CFG) of one or more basic blocks. In HIR, the contents of a region are in single-static assignment (SSA) form, meaning that values may only be defined once, definitions must dominate uses, and operations in the CFG described by the region are executed one-by-one, from the entry block of the region, until control exits the region (e.g. via <code>ret</code> or some other terminator instruction).</p> <p>The order of operations in the region closely corresponds to their scheduling order, though the code generator may reschedule operations when it is safe - and more efficient - to do so.</p> <p>Operations in a region may introduce nested regions. For example, the body of a function consists of a single region, and it might contain an <code>if</code> operation that defines two nested regions, one for the true branch, and one for the false branch. Nested regions may access any values in an ancestor region, so long as those values dominate the operation that introduced the nested region. The exception to this are operations which are isolated from above. The regions of such an operation are not permitted to reference anything defined in an outer scope, except via symbols. For example, functions are an operation which is isolated from above.</p> <p>The purpose of regions, is to allow for hierarchical/structured control flow operations. Without them, representing structured control flow in the IR is difficult and error-prone, due to the semantics of SSA CFGs, particularly with regards to analyses like dominance and loops. It is also an important part of what makes operations such a powerful abstraction, as it provides a way to generically represent the concept of something like a function body, without needing to special-case them.</p> <p>A region must always consist of at least one block (the entry block), but not all regions allow multiple blocks. When multiple blocks are present, it implies the presence of unstructured control flow, as the only way to transfer control between blocks is by using unstructured control flow operations, such as <code>br</code>, <code>cond_br</code>, or <code>switch</code>. Structured control flow operations such as <code>if</code>, introduce nested regions consisting of only a single block, as all control flow within a structured control flow op, must itself be structured. The specific rules for a region depend on the semantics of the containing operation.</p>"},{"location":"design/ir/#blocks","title":"Blocks","text":"<p>A block, or basic block, is a set of one or more operations in which there is no control flow, except via the block terminator, i.e. the last operation in the block, which is responsible for transferring control to another block, exiting the current region (e.g. returning from a function body), or terminating program execution in some way (e.g. <code>unreachable</code>).</p> <p>A block may declare block parameters, the only other way to introduce values into the IR, aside from operation results. Predecessors of a block must ensure that they provide arguments for all block parameters when transfering control to the block.</p> <p>Blocks always belong to a region. The first block in a region is called the entry block, and is special in that its block parameters (if any) correspond to whatever arguments the region accepts. For example, the body of a function is a region, and the entry block in that region must have a parameter list that exactly matches the arity and type of the parameters declared in the function signature. In this way, the function parameters are materialized as SSA values in the IR.</p>"},{"location":"design/ir/#values","title":"Values","text":"<p>A value represents terms in a program, temporaries created to store data as it flows through the program. In HIR, which is in SSA form, values are immutable - once created they cannot be changed nor destroyed. This property of values allows them to be reused, rather than recomputed, when the operation that produced them contains no side-effects, i.e. invoking the operation with the same inputs must produce the same outputs. This forms the basis of one of the ways in which SSA IRs can optimize programs.</p> <p>Note</p> <p>One way in which you can form an intuition for values in an SSA IR, is by thinking of them as registers in a virtual machine with no limit to the number of machine registers. This corresponds well to the fact that most values in an IR, are of a type which corresponds to something that can fit in a typical machine register (e.g. 32-bit or 64-bit values, sometimes larger).</p> <p>Values which cannot be held in actual machine registers, are usually managed in the form of heap or stack-allocated memory, with various operations used to allocate, copy/move, or extract smaller values from them. While not strictly required by the SSA representation, this is almost always effectively enforced by the instruction set, which will only consist of instructions whose operands and results are of a type that can be held in machine registers.</p> <p>Value definitions (aka \u201cdefs\u201d) can be introduced in two ways:</p> <ol> <li>Block parameters. Most notably, the entry block for function bodies materializes the function parameters as values via block parameters. Block parameters are also used at places in the CFG where two definitions for a single value are joined together. For example, if the value assigned to a variable in the source language is assigned conditionally, then in the IR, there will be a block with a parameter corresponding to the value of that variable after it is assigned. All uses after that point, would refer to that block parameter, rather than the value from a specific branch. Similarly, loop-carried variables, such as an iteration count, are typically manifested as block parameters of the block corresponding to the loop header.</li> <li>Operation results. The most common way in which values are introduced.</li> </ol> <p>Values have uses corresponding to operands or successor arguments (special operands which are used to satisfy successor block parameters). As a result, values also have users, corresponding to the specific operation and operand forming a _use.</p> <p>All uses of a value must be dominated by its definition. The IR is invalid if this rule is ever violated.</p>"},{"location":"design/ir/#operands","title":"Operands","text":"<p>An operand is a value or immediate used as an argument to an operation.</p> <p>Beyond the semantics of any given operation, operand ordering is only significant in so far as it is used as the order in which those items are expected to appear on the operand stack once lowered to Miden Assembly. The earlier an operand appears in the list of operands for an operation, the closer to the top of the operand stack it will appear.</p> <p>Similarly, the ordering of operand results also correlates to the operand stack order after lowering. Specifically, the earlier a result appears in the result list, the closer to the top of the operand stack it will appear after the operation executes.</p>"},{"location":"design/ir/#immediates","title":"Immediates","text":"<p>An immediate is a literal value, typically of integral type, used as an operand. Not all operations support immediates, but those that do, will typically use them to attempt to perform optimizations only possible when there is static information available about the operands. For example, multiplying any number by 2, will always produce an even number, so a sequence such as <code>mul.2 is_odd</code> can be folded to <code>false</code> at compile-time, allowing further optimizations to occur.</p> <p>Immediates are separate from constants, in that immediates are constants, but specifically constants which are valid operand values.</p>"},{"location":"design/ir/#attributes","title":"Attributes","text":"<p>An attribute is (typically optional) metadata attached to an IR entity. In HIR, attributes can be attached to functions, global variables, and operations.</p> <p>Attributes are stored as a set of arbitrary key-value data, where values can be one of four types:</p> <ul> <li><code>unit</code>, Attributes of this value type are usually \u201cmarker\u201d attributes, i.e. they convey their information simply by being present.</li> <li><code>bool</code>, Attributes of this value type are somewhat similar to those of <code>unit</code> type, but by carrying a boolean value, they can be used to convey both positive and negative meaning. For example, you might want to support explicit inlining with <code>#[inline(true)]</code>, and prevent any form of inlining with <code>#[inline(false)]</code>. Here, <code>unit</code> would be insufficient to describe both options under a single attribute.</li> <li><code>int</code>, Attributes of this value type are used to convey numeric metadata. For example, inliner thresholds, or some other kind of per-operation limits.</li> <li><code>string</code>, Attributes of this value type are useed to convey arbitrary values. Most commonly you might see this type with things that are enum-like, e.g. <code>#[cc(fast)]</code> to specify a particular calling convention for a function.</li> </ul> <p>Some attributes are \u201cfirst-class\u201d, in that they are defined as part of an operation. For example, the calling convention of a function is an intrinsic attribute of a function, and feels like a native part of the <code>Function</code> API - rather than having to look up the attribute, and cast the value to a more natural Rust type, you can simply call <code>function.calling_convention()</code>.</p> <p>Attributes are not heavily used at this time, but are expected to serve more purposes in the future as we increase the amount of information frontends need to convey to the compiler backend.</p>"},{"location":"design/ir/#traits","title":"Traits","text":"<p>A trait defines some behavior that can be implemented by an operation. This allows operations to operated over generically in an analysis or rewrite, rather than having to handle every possible concrete operation type. This makes passes less fragile to changes in the IR in general, and allows the IR to be extended without having to update every single place where operations are handled.</p> <p>An operation can be cast to a specific trait that it implements, and trait instances can be downcast to the concrete operation type if known.</p> <p>There are a handful of built-in traits, used to convey certain semantic information about the operations they are attached to, and in particular, are used to validate those operations, for example:</p> <ul> <li><code>IsolatedFromAbove</code>, a marker trait that indicates that regions of the operation it is attached to cannot reference items from any parents, except via symbols.</li> <li><code>Terminator</code>, a marker trait for operations which are valid block terminators</li> <li><code>ReturnLike</code>, a trait that describes behavior shared by instructions that exit from an enclosing region, \u201creturning\u201d the results of executing that region. The most notable of these is <code>ret</code>, but <code>yield</code> used by the structured control flow ops is also return-like in nature.</li> <li><code>BranchOp</code>, a trait that describes behavior shared by all unstructured control-flow branch instructions, e.g. <code>br</code>, <code>cond_br</code>, and <code>switch</code>.</li> <li><code>ConstantLike</code>, a marker trait for operations that produce a constant value</li> <li><code>Commutative</code>, a marker trait for binary operations that exhibit commutativity, i.e. the order of the operands can be swapped without changing semantics.</li> </ul> <p>There are others as well, responsible for aiding in type checking, decorating operations with the types of side effects they do (or do not) exhibit, and more.</p>"},{"location":"design/ir/#successors-and-predecessors","title":"Successors and Predecessors","text":"<p>The concept of predecessor and successor corresponds to a parent/child relationship in a control-flow graph (CFG), where edges in the graph are directed, and describe the order in which control flows through the program. If a node \\(A\\) transfers control to a node \\(B\\) after it is finished executing, then \\(A\\) is a predecessor of \\(B\\), and \\(B\\) is a successor of \\(A\\).</p> <p>Successors and predecessors can be looked at from two similar, but slightly different, perspectives:</p> <ol> <li>In terms of operations. In an SSA CFG, operations in a basic block are executed in order, and thus the successor of an operation in the block, is the next operation to be executed in that block, with the predecessor being the inverse of that relationship. At basic block boundaries, the successor(s) of the terminator operation, are the set of operations to which control can be transferred. Likewise, the predecessor(s) of the first operation in a block, are the set of terminators which can transfer control to the containing block. This is the most precise, but is not quite as intuitive as the alternative.</li> <li>In terms of blocks. The successor(s) of a basic block, are the set of blocks to which control may be transferred when exiting the block. Likewise, the precessor(s) of a block, are the set of blocks which can transfer control to it. We are most frequently dealing with the concept of successors and predecessors in terms of blocks, as it allows us to focus on the interesting parts of the CFG. For example, the dominator tree and loop analyses, are constructed in terms of a block-oriented CFG, since we can trivially derive dominance and loop information for individual ops from their containing blocks.</li> </ol> <p>Typically, you will see successors as a pair of <code>(block_id, &amp;[value_id])</code>, i.e. the block to which control is transferred, and the set of values being passed as block arguments. On the other hand, predecessors are most often a pair of <code>(block_id, terminator_op_id)</code>, i.e. the block from which control originates, and the specific operation responsible.</p>"},{"location":"design/ir/#dominance-relation","title":"Dominance Relation","text":"<p>In an SSA IR, the concept of dominance is of critical importance. Dominance is a property of the relationship between two or more entities and their respective program points. For example, between the use of a value as an operand for an operation, and the definition of that value; or between a basic block and its successors. The dominance property is anti-symmetric, i.e. if \\(A\\) dominates \\(B\\), then \\(B\\) cannot dominate \\(A\\), unless \\(A = B\\). Put simply:</p> <p>Given a control-flow graph \\(G\\), and a node \\(A \\in G\\), then \\(\\forall B \\in G\\), \\(A dom B\\) if all paths to \\(B\\) from the root of \\(G\\), pass through \\(A\\).</p> <p>Furthermore, \\(A\\) strictly dominates \\(B\\), if \\(A \\neq B\\).</p> <p>An example of why dominance is an important property of a program, can be seen when considering the meaning of a program like so (written in pseudocode):</p> <pre><code>if (...) {\n  var a = 1;\n}\n\nfoo(a)\n</code></pre> <p>Here, the definition of <code>a</code> does not dominate its usage in the call to <code>foo</code>. If the conditional branch is ever false, <code>a</code> is never defined, nor initialized - so what should happen when we reach the call to <code>foo</code>?</p> <p>In practice, of course, such a program is rarely possible to expresss in a high-level language, however in a low-level CFG, it is possible to reference values which are defined somewhere in the graph, but in such a way that is not legal according to the \u201cdefinitions must dominate uses\u201d rule of SSA CFGs. The dominance property is what we use to validate the correctness of the IR, as well as evaluate the range of valid transformations that can be applied to the IR. For example, we might determine that it is valid to move an expression into a specific <code>if/then</code> branch, because it is only used in that branch - the dominance property is how we determine that there are paths through the program in which the result of the expression is unused, as well as what program points represent the nearest point to one of its uses that still dominates all of the uses.</p> <p>There is another useful notion of dominance, called post-dominance, which can be described much like the regular notion of dominance, except in terms of paths to the exit of the CFG, rather than paths from the entry:</p> <p>Given a control-flow graph \\(G\\), and a node $A \\in \\(G\\), then \\(\\forall B \\in G\\), \\(A pdom B\\) if all paths through \\(B\\) that exit the CFG, must flow through \\(A\\) first.</p> <p>Furthermore, \\(A\\) strictly post-dominates \\(B\\) if \\(A \\neq B\\).</p> <p>The notion of post-dominance is important in determining the applicability of certain transformations, in particular with loops.</p>"},{"location":"design/ir/#structure","title":"Structure","text":"<p>The hierarchy of HIR looks like so:</p> <pre><code>    Component &lt;- Imports &lt;- Interface\n        |\n        v\n     Exports\n        |\n        v\n    Interface\n        |\n        v\n      Module ---------\n        |              |\n        v              v\n    Function/Op     Global Variable\n        |\n        v\n   -- Region\n  |     |\n  |     v\n  |   Block -&gt; Value &lt;--\n  |     |        |      |\n  |     |        v      |\n  |     |      Operand  |\n  |     v        |      |\n   &gt; Operation &lt;-       |\n        |               |\n        v               |\n      Result -----------\n</code></pre> <p>In short:</p> <ul> <li>A component imports dependencies in the form of interfaces</li> <li>A component exports at least one interface.</li> <li>An interface is concretely implemented with a module.</li> <li>A module contains function and global variable definitions, and imports them from the set of interfaces available to the component.</li> <li>A function, as a type of operation, consists of a body region.</li> <li>A region consists of at least one block, that may define values in the form of block parameters.</li> <li>A block consists of operations, whose results introduce new values, and whose operands are values introduced either as block parameters or the results of previous operations.</li> <li>An operation may contain nested regions, with associated blocks and operations.</li> </ul>"},{"location":"design/ir/#passes","title":"Passes","text":"<p>A pass is effectively a fancy function with a specific signature and some constraints on its semantics. There are three primary types of passes: analysis, rewrite, and conversion. These three pass types have different signatures and semantics, but play symbiotic roles in the compilation pipeline.</p> <p>There are two abstractions over all passes, used and extended by the three types described above:</p> <ul> <li>The <code>Pass</code> trait, which provides an abstraction suitable for describing any type of compiler pass used by <code>midenc</code>. It primarily exists to allow writing pass-generic helpers.</li> <li>The <code>PassInfo</code> trait, which exists to provide a common interface for pass metadata, such as the name, description, and command-line flag prefix. All passes must implement this trait.</li> </ul>"},{"location":"design/ir/#analyses","title":"Analyses","text":"<p>Analysis of the IR is expressed in the form of a specialized pass, an <code>Analysis</code>, and an <code>AnalysisManager</code>, which is responsible for computing analyses on demand, caching them, and invalidating the relevant parts of the cache when the IR changes. Analyses are expressed in terms of a specific entity, such as <code>Function</code>, and are cached based on the unique identity of that entity.</p> <p>An analysis is responsible for computing some fact about the given IR entity it is given. Facts typically include things such as: computing dominance, identifying loops and their various component parts, reachability, liveness, identifying unused (i.e. dead) code, and much more.</p> <p>To do this, analyses are given an immutable reference to the IR in question; a reference to the current <code>AnalysisManager</code>, so that the results of other analyses can be consulted; and a reference to the current compilation <code>Session</code> for access to configuration relevant to the analysis.</p> <p>Analysis results are computed as an instance of <code>Self</code>. This provides structure to the analysis results, and provides a place to implement helpful functionality for querying the results.</p> <p>A well-written analysis should be based purely off the inputs given to <code>Analysis::analyze</code>, and ideally be based on some formalism, so that properties of the analysis can be verified. Most of the analyses in HIR today, are based on the formalisms underpinning dataflow analysis, e.g. semi-join lattices.</p>"},{"location":"design/ir/#rewrites","title":"Rewrites","text":"<p>Rewrites are a type of pass which mutate the IR entity to which they are applied. They can be chained (via the <code>chain</code> method on the <code>RewritePass</code> trait) to form rewrite pipelines, called a <code>RewriteSet</code>. A <code>RewriteSet</code> manages executing each rewrite in the set, and coordinating with the <code>AnalysisManager</code> between rewrites.</p> <p>Rewrites are given a mutable reference to the IR they should apply to; the current <code>AnalysisManager</code> so that analyes can be consulted (or computed) to facilitate the rewrite; and the current compilation <code>Session</code>, for configuration.</p> <p>Rewrites must leave the IR in a valid state. Rewrites are also responsible for indicating, via the <code>AnalysisManager</code>, which analyses can be preserved after applying the rewrite. A rewrite that makes no changes, should mark all analyses preserved, to avoid recomputing the analysis results the next time they are requested. If an analysis is not explicitly preserved by a rewrite, it will be invalidated by the containing <code>RewriteSet</code>.</p> <p>Rewrite passes written for a <code>Function</code>, can be adapted for application to a <code>Module</code>, using the <code>ModuleRewriteAdapter</code>. This makes writing rewrites for use in the main compiler pipeline, as simple as defining it for a <code>Function</code>, and then using the <code>ModuleRewriteAdapter</code> to add the rewrite to the pipeline.</p> <p>A well-written rewrite pass should only use data available in the IR itself, or analyses in the provided <code>AnalysisManager</code>, to drive application of the rewrite. Additionally, rewrites should focus on a single transformation, and rely on chaining rewrites to orchestrate more complex transformations composed of multiple stages. Lastly, the rewrite should ideally have a logical proof of its safety, or failing that, a basis in some formalism that can be suitably analyzed and/or tested. If a rewrite cannot be described in such a way, it will be very difficult to provide guarantees about the code produced by the transformation. This makes it hard to be confident in the rewrite (and by extension, the compiler), and impossible to verify.</p>"},{"location":"design/ir/#conversions","title":"Conversions","text":"<p>Conversions are a type of pass which converts between intermediate representations, or more abstractly, between dialects.</p> <p>The concept of a dialect is focused primarily on semantics, and less so on concrete representations. For example, source and target dialects might share the same underlying IR, with the target dialect having a more restricted set of legal operations, possibly with stricter semantics.</p> <p>This brings us to the concept of legalization, i.e. converting all illegal operations in the IR into legal equivalents. Each dialect defines the set of operations which it considers legal. The concept of legality is mostly important when the same underlying IR is used across multiple dialects, as is the case with HIR.</p> <p>There are two types of conversion passes in HIR: dialect conversion, and translation:</p> <ul> <li>Dialect conversion is used at various points in the compilation pipeline to simplify the IR for later passes. For example, Miden Assembly has no way to represent multi-way branches, such as implemented by <code>switch</code>. At a certain point, we switch to a dialect where <code>switch</code> is illegal, so that further passes can be written as if <code>switch</code> doesn\u2019t exist. Yet another dialect later in the pipeline, makes all unstructured control flow illegal, in preparation for translation to Miden Assembly, which has no unstructured control flow operators.</li> <li>Translation refers to a conversion from one IR to a completely different one. Currently, the only translation we have, is the one responsible for translating from HIR to Miden Assembly. In the future, we hope to also implement frontends as translations to HIR, but that is not currently the case. Translations are currently implemented as simple passes that take in some IR as input, and produce whatever as output.</li> </ul> <p>Dialect conversions are implemented in the form of generic conversion infrastructure. A dialect conversion is described as a set of conversion patterns, which define what to do when a specific operation is seen in the input IR; and the set of operations which are legal in the target dialect. The conversion driver is responsible for visiting the IR, repetitively applying any matched conversion patterns until a fixpoint is reached, i.e. no more patterns are matched, or a conversion pattern fails to apply successfully. If any illegal operations are found which do not have corresponding conversion patterns, then a legalization error is raised, and the conversion overall fails.</p>"},{"location":"design/ir/#usage","title":"Usage","text":"<p>Let\u2019s get into the gritty details of how the compiler works, particularly in relation to HIR.</p> <p>The entry point for compilation, generally speaking, is the driver. The driver is what is responsible for collecting compiler inputs, including configuration, from the user, instantiating a <code>Session</code>, and then invoking the compiler frontend with those items.</p> <p>The first stage of compilation is parsing, in which each input is converted to HIR by an appropriate frontend. For example, Wasm modules are loaded and translated to HIR using the Wasm frontend. The purpose of this stage is to get all inputs into HIR form, for subsequent stages. The only exception to this are MASM sources, which are assembled to MAST directly, and then set aside until later in the pipeline when we go to assemble the final artifact.</p> <p>The second stage of compilation is semantic analysis. This is the point where we validate the HIR we have so far, and ensure that there are no obvious issues that will cause compilation to fail unexpectedly later on. In some cases, this stage is skipped, as we have already validated the IR in the frontend.</p> <p>The third stage of compilation is linking. This is where we gather together all of the inputs, as well as any compiler options that tell us what libraries to link against, and where to search for them, and then ensure that there are no missing inputs, undefined symbols, or incompatible type signatures. The output of this stage is a well-formed component.</p> <p>The fourth stage of compilation is rewriting, in which all of the rewrite passes we wish to apply to the IR, are applied. You could also think of this stage as a combination of optimization and preparing for codegen.</p> <p>The fifth stage of compilation is codegen, where HIR is translated to Miden Assembly.</p> <p>The final stage of compilation is assembly, where the Miden Assembly we produced, along with any other Miden Assembly libraries, are assembled to MAST, and then packaged in the Miden package format.</p> <p>The <code>Session</code> object contains all of the important compiler configuration and exists for the duration of a compiler invocation. In addition to this, there is a <code>Context</code> object, which is used to allocate IR entities contained within a single <code>Module</code>. The context of each <code>Module</code> is further subdivided by <code>Function</code>, in the form of <code>FunctionContext</code>, from which all function-local IR entities are allocated. This ensures that each <code>Function</code> gets its own set of values, blocks, and regions, while sharing <code>Module</code>-wide entities, such as constants and symbols.</p> <p>Operations are allocated from the nearest <code>Context</code>, and use that context to allocate and access IR entities used by the operation.</p> <p>The <code>Context</code> object is pervasive, it is needed just about anywhere that IR entities are used, to allow accessing data associated with those entities. Most entity references are integer ids, which uniquely identify the entity, but provide no access to them without going through the <code>Context</code>.</p> <p>This is a bit awkward, but is easier to work with in Rust. The alternative is to rely on dynamically-checked interior mutability inside reference-counted allocations, e.g. <code>Rc&lt;RefCell&lt;T&gt;&gt;</code>. Not only is this similarly pervasive in terms of how APIs are structured, but it loses some of the performance benefits of allocating IR objects close together on the heap.</p> <p>The following is some example code in Rust, demonstrating how it might look to create a component in HIR and work with it.</p> <pre><code>use midenc_hir::*;\n\n/// Defining Ops\n\n/// `Add` is a binary integral arithmetic operator, i.e. `+`\n///\n/// It consists of two operands, which must be of the same type, and produces a result that\n/// is also of that type.\n///\n/// It supports various types of overflow semantics, see `Overflow`.\npub struct Add {\n    op: Operation,\n}\nimpl Add {\n    pub fn build(overflow: Overflow, lhs: Operand, rhs: Operand, span: SourceSpan, context: &amp;mut Context) -&gt; OpId {\n        let ctrl_ty = context.value_type(lhs);\n        let mut builder = OpBuilder::&lt;Self&gt;::new(context);\n        // Set the source span for this op\n        builder.with_span(span);\n        // We specify the concrete operand values\n        builder.with_operands([lhs, rhs]);\n        // We specify results in terms of types, and the builder will materialize values\n        // for the instruction results based on those types.\n        builder.with_results([ctrl_ty]);\n        // We must also specify operation attributes, e.g. overflow behavior\n        //\n        // Attribute values must implement `AttributeValue`, a trait which represents the encoding\n        // and decoding of a type as an attribute value.\n        builder.with_attribute(\"overflow\", overflow);\n        // Add op traits that this type implements\n        builder.with_trait::&lt;Commutative&gt;();\n        builder.with_trait::&lt;SameTypeOperands&gt;();\n        builder.with_trait::&lt;Canonicalize&gt;();\n        // Instantiate the op\n        //\n        // NOTE: In order to use `OpBuilder`, `Self` must implement `Default` if it has any other\n        // fields than the underlying `Operation`. This is because the `OpBuilder` will construct\n        // a default instance of the type when allocating it, and according to Rust rules, any\n        // subsequent reference to the type requires that all fields were properly initialized.\n        builder.build()\n    }\n\n    /// The `OpOperand` type abstracts over information about a given operand, such as whether it\n    /// is a value or immediate, and its type. It also contains the link for the operand in the\n    /// original `Value`'s use list.\n    pub fn lhs(&amp;self) -&gt; &amp;OpOperand {\n        &amp;self.op.operands[0]\n    }\n\n    pub fn rhs(&amp;self) -&gt; &amp;OpOperand {\n        &amp;self.op.operands[1]\n    }\n\n    /// The `OpResult` type abstracts over information about a given result, such as whether it\n    /// is a value or constant, and its type.\n    pub fn result(&amp;self) -&gt; &amp;OpResult {\n        &amp;self.op.results[0]\n    }\n\n    /// Attributes of the op can be reified from the `AttributeSet` of the underlying `Operation`,\n    /// using `get_attribute`, which will use the `AttributeValue` implementation for the type to\n    /// reify it from the raw attribute data.\n    pub fn overflow(&amp;self) -&gt; Overflow {\n        self.op.get_attribute(\"overflow\").unwrap_or_default()\n    }\n}\n/// All ops must implement this trait, but most implementations will look like this\nimpl Op for Add {\n    type Id = OpId;\n\n    fn id(&amp;self) -&gt; Self::Id { self.op.key }\n    fn name(&amp;self) -&gt; &amp;'static str { \"add\" }\n    fn as_operation(&amp;self) -&gt; &amp;Operation { &amp;self.op}\n    fn as_operation_mut(&amp;mut self) -&gt; &amp;mut Operation { &amp;mut self.op}\n}\n/// Marker trait used to indicate an op exhibits the commutativity property\nimpl Commutative for Add {}\n/// Marker trait used to indicate that operands of this op should all be the same type\nimpl SameTypeOperands for Add {}\n/// Canonicalization is optional, but encouraged when an operation has a canonical form.\n///\n/// This is applied after transformations which introduce or modify an `Add` op, and ensures\n/// that it is in canonical form.\n///\n/// Canonicalizations ensure that pattern-based rewrites can be expressed in terms of the\n/// canonical form, rather than needing to account for all possible variations.\nimpl Canonicalize for Add {\n    fn canonicalize(&amp;mut self) {\n        // If `add` is given an immediate operand, always place it on the right-hand side\n        if self.lhs().is_immediate() {\n            if self.rhs().is_immediate() {\n                return;\n            }\n            self.op.operands.swap(0, 1);\n        }\n    }\n}\n/// Ops can optionally implement [PrettyPrint] and [PrettyParser], to allow for a less verbose\n/// textual representation. If not implemented, the op will be printed using the generic format\n/// driven by the underlying `Operation`.\nimpl formatter::PrettyPrint for Add {\n    fn render(&amp;self) -&gt; formatter::Document {\n        use formatter::*;\n\n        let opcode = match self.overflow() {\n            Overflow::Unchecked =&gt; const_text(\"add\"),\n            Overflow::Checked =&gt; const_text(\"add.checked\"),\n            Overflow::Wrapping =&gt; const_text(\"add.wrapping\"),\n            Overflow::Overflowing =&gt; const_text(\"add.overflowing\"),\n        };\n        opcode + const_text(\" \") + display(self.lhs()) + const_text(\", \") + display(self.rhs())\n    }\n}\nimpl parsing::PrettyParser for Add {\n    fn parse(s: &amp;str, context: &amp;mut Context) -&gt; Result&lt;Self, Report&gt; {\n        todo!(\"not shown here\")\n    }\n}\n\n/// Constructing Components\n\n// An interface can consist of functions, global variables, and potentially types in the future\nlet mut std = Interface::new(\"std\");\nstd.insert(\"math::u64/add_checked\", FunctionType::new([Type::U64, Type::U64], [Type::U64]));\n\nlet test = Interface::new(\"test\");\ntest.insert(\"run\", FunctionType::new([], [Type::U32]));\n\n// A component is instantiated empty\nlet mut component = Component::new(\"test\");\n\n// You must then declare the interfaces that it imports and exports\ncomponent.import(std.clone());\ncomponent.export(test.clone());\n\n// Then, to actually define a component instance, you must define modules which implement\n// the interfaces exported by the component\nlet mut module = Module::new(\"test\");\nlet mut run = module.define(\"run\", FunctionType::new([], [Type::U32]));\n//... build 'run' function\n\n// And add them to the component, like shown here. Here, `module` is added to the component as an\n// implementation of the `test` interface\ncomponent.implement(test, module);\n\n// Modules can also be added to a component without using them to implement an interface,\n// in which case they are only accessible from other modules in the same component, e.g.:\nlet foo = Module::new(\"foo\");\n// Here, the 'foo' module will only be accessible from the 'test' module.\ncomponent.add(foo);\n\n// Lastly, during compilation, imports are resolved by linking against the components which\n// implement them. The linker step identifies the concrete paths of each item that provides\n// an imported symbol, and rewrites the generic interface path with the concrete path of the\n// item it was resolved to.\n\n/// Visiting IR\n\n// Visiting the CFG\n\nlet entry = function.body().entry();\nlet mut worklist = VecDeque::from_iter([entry]);\n\nwhile let Some(next) = worklist.pop_front() {\n    // Ignore blocks we've already visited\n    if !visited.insert(next) {\n        continue;\n    }\n    let terminator = context.block(next).last().unwrap();\n    // Visit all successors after this block, if the terminator branches to another block\n    if let Some(branch) = terminator.downcast_ref::&lt;Branch&gt;() {\n        worklist.extend(branch.successors().iter().map(|succ| succ.block));\n    }\n    // Visit the operations in the block bottom-up\n    let mut current_op = terminator;\n    while let Some(op) = current_op.prev() {\n        current_op = op;\n    }\n}\n\n// Visiting uses of a value\n\nlet op = function.body().entry().first().unwrap();\nlet result = op.results().first().unwrap();\nassert!(result.is_used());\nfor user in result.uses() {\n    dbg!(user);\n}\n\n// Applying a rewrite pattern to every match in a function body\n\nstruct FoldAdd;\nimpl RewritePattern for FoldAdd {\n    fn matches(&amp;self, op: &amp;dyn Op) -&gt; bool {\n        op.is::&lt;Add&gt;()\n    }\n\n    fn apply(&amp;mut self, op: &amp;mut dyn Op) -&gt; RewritePatternResult {\n        let add_op = op.downcast_mut::&lt;Add&gt;().unwrap();\n        if let Some(lhs) = add_op.lhs().as_immediate() {\n            if let Some(rhs) = add_op.rhs().as_immediate() {\n                let result = lhs + rhs;\n                return Ok(RewriteAction::ReplaceAllUsesWith(add_op.result().value, result));\n            }\n        }\n        Ok(RewriteAction::None)\n    }\n}\n</code></pre>"},{"location":"design/overview/","title":"Compiler architecture","text":"<p>This is an index of various design documents for the compiler and its components. Some of these are planned topics, and some have documentation that hasn\u2019t been polished up yet. We\u2019ll slowly start to flesh out the documentation in this section as the compiler matures.</p> <ul> <li>Driver</li> <li>Frontends</li> <li>Intermediate Representation (HIR)</li> <li>Data Layout</li> <li>Inline Assembly</li> <li>Analysis</li> <li>Rewrite Passes</li> <li>Code Generation</li> <li>Instruction Scheduling</li> <li>Instruction Selection</li> <li>Operand Stack Management</li> <li>Packaging</li> </ul>"},{"location":"guides/develop_miden_in_rust/","title":"Developing Miden programs in Rust","text":"<p>This chapter will walk through how to develop Miden programs in Rust using the standard library provided by the <code>miden-stdlib-sys</code> crate (see the README.</p>"},{"location":"guides/develop_miden_in_rust/#getting-started","title":"Getting started","text":"<p>Import the standard library from the <code>miden-stdlib-sys</code> crate:</p> <pre><code>use miden_stdlib_sys::*;\n</code></pre>"},{"location":"guides/develop_miden_in_rust/#using-felt-field-element-type","title":"Using <code>Felt</code> (field element) type","text":"<p>The <code>Felt</code> type is a field element type that is used to represent the field element values of the Miden VM.</p> <p>To initialize a <code>Felt</code> value from an integer constant checking the range at compile time, use the <code>felt!</code> macro:</p> <pre><code>let a = felt!(42);\n</code></pre> <p>Otherwise, use the <code>Felt::new</code> constructor:</p> <pre><code>let a = Felt::new(some_integer_var).unwrap();\n</code></pre> <p>The constructor returns an error if the value is not a valid field element, e.g. if it is not in the range <code>0..=M</code> where <code>M</code> is the modulus of the field (2^64 - 2^32 + 1).</p> <p>The <code>Felt</code> type implements the standard arithmetic operations, e.g. addition, subtraction, multiplication, division, etc. which are accessible through the standard Rust operators <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, etc. All arithmetic operations are wrapping, i.e. performed modulo <code>M</code>.</p> <p>TODO: Add examples of using operations on <code>Felt</code> type and available functions (<code>assert*</code>, etc.).</p>"},{"location":"guides/develop_miden_rollup_accounts_and_note_scripts_in_rust/","title":"Developing Miden rollup accounts and note scripts in Rust","text":"<p>This chapter walks you through how to develop Miden rollup accounts and note scripts in Rust using the Miden SDK crate.</p>"},{"location":"guides/rust_to_wasm/","title":"Compiling Rust To WebAssembly","text":"<p>This chapter will walk you through compiling a Rust crate to a WebAssembly (Wasm) module in binary (i.e. <code>.wasm</code>) form. The Miden compiler has a frontend which can take such modules and compile them on to Miden Assembly, which will be covered in the next chapter.</p>"},{"location":"guides/rust_to_wasm/#setup","title":"Setup","text":"<p>First, let\u2019s set up a simple Rust project that contains an implementation of the Fibonacci function (I know, it\u2019s overdone, but we\u2019re trying to keep things as simple as possible to make it easier to show the results at each step, so bear with me):</p> <p>Start by creating a new library crate:</p> <pre><code>cargo new --lib wasm-fib &amp;&amp; cd wasm-fib\n</code></pre> <p>To compile to WebAssembly, you must have the appropriate Rust toolchain installed, so let\u2019s add a toolchain file to our project root so that <code>rustup</code> and <code>cargo</code> will know what we need, and use them by default:</p> <pre><code>cat &lt;&lt;EOF &gt; rust-toolchain.toml\n[toolchain]\nchannel = \"stable\"\ntargets = [\"wasm32-wasip1\"]\nEOF\n</code></pre> <p>Next, edit the <code>Cargo.toml</code> file as follows:</p> <pre><code>[package]\nname = \"wasm-fib\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\n# Build this crate as a self-contained, C-style dynamic library\n# This is required to emit the proper Wasm module type\ncrate-type = [\"cdylib\"]\n\n[dependencies]\n# Use a tiny allocator in place of the default one, if we want\n# to make use of types in the `alloc` crate, e.g. String. We\n# don't need that now, but it's good information to have in hand.\n#miden-sdk-alloc = \"0.0.5\"\n\n# When we build for Wasm, we'll use the release profile\n[profile.release]\n# Explicitly disable panic infrastructure on Wasm, as\n# there is no proper support for them anyway, and it\n# ensures that panics do not pull in a bunch of standard\n# library code unintentionally\npanic = \"abort\"\n# Enable debug information so that we get useful debugging output\ndebug = true\n# Optimize the output for size\nopt-level = \"z\"\n</code></pre> <p>Most of these things are done to keep the generated code size as small as possible. Miden is a target where the conventional wisdom about performance should be treated very carefully: we\u2019re almost always going to benefit from less code, even if conventionally that code would be less efficient, simply due to the difference in proving time accumulated due to extra instructions. That said, there are no hard and fast rules, but these defaults are good ones to start with.</p> <p>Tip</p> <p>We reference a simple bump allocator provided by <code>miden-sdk-alloc</code> above, but any simple allocator will do. The trade offs made by these small allocators are not generally suitable for long-running, or allocation-heavy applications, as they \u201cleak\u201d memory (generally because they make little to no attempt to recover freed allocations), however they are very useful for one-shot programs that do minimal allocation, which is going to be the typical case for Miden programs.</p> <p>Next, edit <code>src/lib.rs</code> as shown below:</p> <pre><code>// Do not link against libstd (i.e. anything defined in `std::`)\n#![no_std]\n\n// However, we could still use some standard library types while\n// remaining no-std compatible, if we uncommented the following lines:\n//\n// extern crate alloc;\n// use alloc::{string::String, vec::Vec};\n\n// If we wanted to use the types mentioned above, it would also be\n// a good idea to use the allocator we pulled in as a dependency\n// in Cargo.toml, like so:\n//#[global_allocator]\n//static ALLOC: miden_sdk_alloc::BumpAlloc = miden_sdk_alloc::BumpAlloc::new();\n\n// Required for no-std crates\n#[panic_handler]\nfn panic(_info: &amp;core::panic::PanicInfo) -&gt; ! {\n    // Compiles to a trap instruction in WebAssembly\n    core::arch::wasm32::unreachable()\n}\n\n// Marking the function no_mangle ensures that it is exported\n// from the compiled binary as `fib`, otherwise it would have\n// a mangled name that has no stable form.\n//\n// You can specify a different name from the library than the\n// name in the source code using the `#[export_name = \"foo\"]`\n// attribute, which will make the function callable as `foo`\n// externally (in this example)\n#[no_mangle]\npub fn fib(n: u32) -&gt; u32 {\n    let mut a = 0;\n    let mut b = 1;\n    for _ in 0..n {\n        let c = a + b;\n        a = b;\n        b = c;\n    }\n    a\n}\n</code></pre> <p>This exports our <code>fib</code> function from the library, making it callable from within a larger Miden program.</p> <p>All that remains is to compile to WebAssembly:</p> <pre><code>cargo build --release --target=wasm32-wasip1\n</code></pre> <p>This places a <code>wasm_fib.wasm</code> file under the <code>target/wasm32-wasip1/release/</code> directory, which we can then examine with wasm2wat to set the code we generated:</p> <pre><code>wasm2wat target/wasm32-wasip1/release/wasm_fib.wasm\n</code></pre> <p>Which dumps the following output (may differ slightly on your machine, depending on the specific compiler version):</p> <pre><code>(module $wasm_fib.wasm\n  (type (;0;) (func (param i32) (result i32)))\n  (func $fib (type 0) (param i32) (result i32)\n    (local i32 i32 i32)\n    i32.const 0\n    local.set 1\n    i32.const 1\n    local.set 2\n    loop (result i32)  ;; label = @1\n      local.get 2\n      local.set 3\n      block  ;; label = @2\n        local.get 0\n        br_if 0 (;@2;)\n        local.get 1\n        return\n      end\n      local.get 0\n      i32.const -1\n      i32.add\n      local.set 0\n      local.get 1\n      local.get 3\n      i32.add\n      local.set 2\n      local.get 3\n      local.set 1\n      br 0 (;@1;)\n    end)\n  (memory (;0;) 16)\n  (global $__stack_pointer (mut i32) (i32.const 1048576))\n  (export \"memory\" (memory 0))\n  (export \"fib\" (func $fib)))\n</code></pre> <p>Success!</p>"},{"location":"guides/rust_to_wasm/#next-steps","title":"Next steps","text":"<p>In Compiling WebAssembly to Miden Assembly, we walk through how to take the WebAssembly module we just compiled, and lower it to Miden Assembly using <code>midenc</code>!</p>"},{"location":"guides/wasm_to_masm/","title":"Compiling WebAssembly to Miden Assembly","text":"<p>This guide will walk you through compiling a WebAssembly (Wasm) module, in binary form (i.e. a <code>.wasm</code> file), to Miden Assembly (Masm), both in its binary package form (a <code>.masp</code> file), and in textual Miden Assembly syntax form (i.e. a <code>.masm</code> file).</p>"},{"location":"guides/wasm_to_masm/#setup","title":"Setup","text":"<p>We will be making use of the example crate we created in Compiling Rust to WebAssembly, which produces a small Wasm module that is easy to examine in Wasm text format, and demonstrates a good set of default choices for a project compiling to Miden Assembly from Rust.</p> <p>In this chapter, we will be compiling Wasm to Masm using the <code>midenc</code> executable, so ensure that you have followed the instructions in the Getting Started with <code>midenc</code> guide and then return here.</p> <p>Note</p> <p>While we are using <code>midenc</code> for this guide, the more common use case will be to use the <code>cargo-miden</code> Cargo extension to handle the gritty details of compiling from Rust to Wasm for you. However, the purpose of this guide is to show you what <code>cargo-miden</code> is handling for you, and to give you a foundation for using <code>midenc</code> yourself if needed.</p>"},{"location":"guides/wasm_to_masm/#compiling-to-miden-assembly","title":"Compiling to Miden Assembly","text":"<p>In the last chapter, we compiled a Rust crate to WebAssembly that contains an implementation of the Fibonacci function called <code>fib</code>, that was emitted to <code>target/wasm32-wasip1/release/wasm_fib.wasm</code>. All that remains is to tell <code>midenc</code> to compile this module to Miden Assembly.</p> <p>Currently, by default, the compiler will emit an experimental package format that the Miden VM does not yet support. We will instead use <code>midenc run</code> to execute the package using the VM for us, but once the package format is stabilized, this same approach will work with <code>miden run</code> as well.</p> <p>We also want to examine the Miden Assembly generated by the compiler, so we\u2019re going to ask the compiler to emit both types of artifacts:</p> <pre><code>midenc compile --emit masm=wasm_fib.masm,masp  target/wasm32-wasip1/release/wasm_fib.wasm\n</code></pre> <p>This will compile our Wasm module to a Miden package with the <code>.masp</code> extension, and also emit the textual Masm to <code>wasm_fib.masm</code> so we can review it. The <code>wasm_fib.masp</code> file will be emitted in the default output directory, which is the current working directory by default.</p> <p>If we dump the contents of <code>wasm_fib.masm</code>, we\u2019ll see the following generated code:</p> <pre><code>export.fib\n  push.0\n  push.1\n  movup.2\n  swap.1\n  dup.1\n  neq.0\n  push.1\n  while.true\n    if.true\n      push.4294967295\n      movup.2\n      swap.1\n      u32wrapping_add\n      dup.1\n      swap.1\n      swap.3\n      swap.1\n      u32wrapping_add\n      movup.2\n      swap.1\n      dup.1\n      neq.0\n      push.1\n    else\n      drop\n      drop\n      push.0\n    end\n  end\nend\n</code></pre> <p>If you compare this to the WebAssembly text format, you can see that this is a fairly faithful translation, but there may be areas where we generate sub-optimal Miden Assembly.</p> <p>Note</p> <p>At the moment the compiler does only minimal optimization, late in the pipeline during codegen, and only in an effort to minimize operand stack management code. So if you see an instruction sequence you think is bad, bring it to our attention, and if it is something that we can solve as part of our overall optimization efforts, we will be sure to do so. There are limits to what we can generate compared to what one can write by hand, particularly because Rust\u2019s memory model requires us to emulate byte-addressable memory on top of Miden\u2019s word-addressable memory, however our goal is to keep this overhead within an acceptable bound in the general case, and easily-recognized patterns that can be simplified using peephole optimization are precisely the kind of thing we\u2019d like to know about, as those kinds of optimizations are likely to produce the most significant wins.</p>"},{"location":"guides/wasm_to_masm/#testing-with-the-miden-vm","title":"Testing with the Miden VM","text":"<p>Note</p> <p>Because the compiler ships with the VM embedded for <code>midenc debug</code>, you can run your program without having to install the VM separately, though you should do that as well, as <code>midenc</code> only exposes a limited set of commands for executing programs, intended for debugging.</p> <p>We can test our compiled program like so:</p> <pre><code>$ midenc run --num-outputs 1 wasm_fib.masp -- 10\n============================================================\nRun program: wasm_fib.masp\n============================================================\nExecuted program with hash 0xe5ba88695040ec2477821b26190e9addbb1c9571ae30c564f5bbfd6cabf6c535 in 19 milliseconds\nOutput: [55]\nVM cycles: 295 extended to 512 steps (42% padding).\n\u251c\u2500\u2500 Stack rows: 295\n\u251c\u2500\u2500 Range checker rows: 67\n\u2514\u2500\u2500 Chiplets rows: 250\n\u251c\u2500\u2500 Hash chiplet rows: 248\n\u251c\u2500\u2500 Bitwise chiplet rows: 0\n\u251c\u2500\u2500 Memory chiplet rows: 1\n\u2514\u2500\u2500 Kernel ROM rows: 0\n</code></pre> <p>Success! We got the expected result of <code>55</code>.</p>"},{"location":"guides/wasm_to_masm/#next-steps","title":"Next steps","text":"<p>This guide is not comprehensive, as we have not yet examined in detail the differences between compiling libraries vs programs, linking together multiple libraries, packages, or discussed some of the more esoteric compiler options. We will be updating this documentation with those details and more in the coming weeks and months, so bear with us while we flesh out our guides!</p>"},{"location":"usage/cargo-miden/","title":"Getting started with Cargo","text":"<p>As part of the Miden compiler toolchain, we provide a Cargo extension, <code>cargo-miden</code>, which provides a template to spin up a new Miden project in Rust, and takes care of orchestrating <code>rustc</code> and <code>midenc</code> to compile the Rust crate to a Miden package.</p>"},{"location":"usage/cargo-miden/#installation","title":"Installation","text":"<p>Warning</p> <p>Currently, <code>midenc</code> (and as a result, <code>cargo-miden</code>), requires the nightly Rust toolchain, so make sure you have it installed first:</p> <pre><code>rustup toolchain install nightly-2025-01-16\n</code></pre> <p>NOTE: You can also use the latest nightly, but the specific nightly shown here is known to work.</p> <p>To install the extension, clone the compiler repo first:</p> <pre><code>git clone https://github.com/0xpolygonmiden/compiler\n</code></pre> <p>Then, run the following in your shell in the cloned repo folder:</p> <pre><code>cargo install --path tools/cargo-miden --locked\n</code></pre> <p>This will take a minute to compile, but once complete, you can run <code>cargo help miden</code> or just <code>cargo miden</code> to see the set of available commands and options.</p> <p>To get help for a specific command, use <code>cargo miden help &lt;command&gt;</code> or <code>cargo miden &lt;command&gt; --help</code>.</p>"},{"location":"usage/cargo-miden/#creating-a-new-project","title":"Creating a new project","text":"<p>Your first step will be to create a new Rust project set up for compiling to Miden:</p> <pre><code>cargo miden new foo\n</code></pre> <p>In this above example, this will create a new directory <code>foo</code>, containing a Cargo project for a crate named <code>foo</code>, generated from our Miden project template.</p> <p>The template we use sets things up so that you can pretty much just build and run. Since the toolchain depends on Rust\u2019s native WebAssembly target, it is set up just like a minimal WebAssembly crate, with some additional tweaks for Miden specifically.</p> <p>Out of the box, you will get a Rust crate that depends on the Miden SDK, and sets the global allocator to a simple bump allocator we provide as part of the SDK, and is well suited for most Miden use cases, avoiding the overhead of more complex allocators.</p> <p>As there is no panic infrastructure, <code>panic = \"abort\"</code> is set, and the panic handler is configured to use the native WebAssembly <code>unreachable</code> intrinsic, so the compiler will strip out all of the usual panic formatting code.</p>"},{"location":"usage/cargo-miden/#compiling-to-miden-package","title":"Compiling to Miden package","text":"<p>Now that you\u2019ve created your project, compiling it to Miden package is as easy as running the following command from the root of the project directory:</p> <pre><code>cargo miden build --release\n</code></pre> <p>This will emit the compiled artifacts to <code>target/miden/release/foo.masp</code>.</p>"},{"location":"usage/cargo-miden/#running-a-compiled-miden-vm-program","title":"Running a compiled Miden VM program","text":"<p>Warning</p> <p>To run the compiled Miden VM program you need to have <code>midenc</code> installed. See <code>midenc</code> docs for the installation instructions.</p> <p>The compiled Miden VM program can be run from the Miden package with the following:</p> <pre><code>midenc run target/miden/release/foo.masp --inputs some_inputs.toml\n</code></pre> <p>See <code>midenc run --help</code> for the inputs file format.</p>"},{"location":"usage/debugger/","title":"Debugging programs","text":"<p>A very useful tool in the Miden compiler suite, is its TUI-based interactive debugger, accessible via the <code>midenc debug</code> command.</p> <p>Warning</p> <p>The debugger is still quite new, and while very useful already, still has a fair number of UX annoyances. Please report any bugs you encounter, and we\u2019ll try to get them patched ASAP!</p>"},{"location":"usage/debugger/#getting-started","title":"Getting started","text":"<p>The debugger is launched by executing <code>midenc debug</code>, and giving it a path to a program compiled by <code>midenc compile</code>. See Program Inputs for information on how to provide inputs to the program you wish to debug. Run <code>midenc help debug</code> for more detailed usage documentation.</p> <p>The debugger may also be used as a library, but that is left as an exercise for the reader for now.</p>"},{"location":"usage/debugger/#example","title":"Example","text":"<pre><code># Compile a program to MAST from a rustc-generated Wasm module\nmidenc compile foo.wasm -o foo.masl\n\n# Load that program into the debugger and start executing it\nmidenc debug foo.masl\n</code></pre>"},{"location":"usage/debugger/#program-inputs","title":"Program inputs","text":"<p>To pass arguments to the program on the operand stack, or via the advice provider, you have two options, depending on the needs of the program:</p> <ol> <li>Pass arguments to <code>midenc debug</code> in the same order you wish them to appear on the stack. That    is, the first argument you specify will be on top of the stack, and so on.</li> <li>Specify a configuration file from which to load inputs for the program, via the <code>--inputs</code> option.</li> </ol>"},{"location":"usage/debugger/#via-command-line","title":"Via command line","text":"<p>To specify the contents of the operand stack, you can do so following the raw arguments separator <code>--</code>. Each operand must be a valid field element value, in either decimal or hexadecimal format. For example:</p> <pre><code>midenc debug foo.masl -- 1 2 0xdeadbeef\n</code></pre> <p>If you pass arguments via the command line in conjunction with <code>--inputs</code>, then the command line arguments will be used instead of the contents of the <code>inputs.stack</code> option (if set). This lets you specify a baseline set of inputs, and then try out different arguments using the command line.</p>"},{"location":"usage/debugger/#via-inputs-config","title":"Via inputs config","text":"<p>While simply passing operands to the <code>midenc debug</code> command is useful, it only allows you to specify inputs to be passed via operand stack. To provide inputs via the advice provider, you will need to use the <code>--inputs</code> option. The configuration file expected by <code>--inputs</code> also lets you tweak the execution options for the VM, such as the maximum and expected cycle counts.</p> <p>An example configuration file looks like so:</p> <pre><code># This section is used for execution options\n[options]\nmax_cycles = 5000\nexpected_cycles = 4000\n\n# This section is the root table for all inputs\n[inputs]\n# Specify elements to place on the operand stack, leftmost element will be on top of the stack\nstack = [1, 2, 0xdeadbeef]\n\n# This section contains input options for the advice provider\n[inputs.advice]\n# Specify elements to place on the advice stack, leftmost element will be on top\nstack = [1, 2, 3, 4]\n\n# The `inputs.advice.map` section is a list of advice map entries that should be\n# placed in the advice map before the program is executed. Entries with duplicate\n# keys are handled on a last-write-wins basis.\n[[inputs.advice.map]]\n# The key for this entry in the advice map\ndigest = '0x3cff5b58a573dc9d25fd3c57130cc57e5b1b381dc58b5ae3594b390c59835e63'\n# The values to be stored under this key\nvalues = [1, 2, 3, 4]\n\n[[inputs.advice.map]]\ndigest = '0x20234ee941e53a15886e733cc8e041198c6e90d2a16ea18ce1030e8c3596dd38''\nvalues = [5, 6, 7, 8]\n</code></pre>"},{"location":"usage/debugger/#usage","title":"Usage","text":"<p>Once started, you will be dropped into the main debugger UI, stopped at the first cycle of the program. The UI is organized into pages and panes, with the main/home page being the one you get dropped into when the debugger starts. The home page contains the following panes:</p> <ul> <li>Source Code - displays source code for the current instruction, if available, with   the relevant line and span highlighted, with syntax highlighting (when available)</li> <li>Disassembly - displays the 5 most recently executed VM instructions, and the current   cycle count</li> <li>Stack Trace - displays a stack trace for the current instruction, if the program was   compiled with tracing enabled. If frames are unavailable, this pane may be empty.</li> <li>Operand Stack - displays the contents of the operand stack and its current depth</li> <li>Breakpoints - displays the set of current breakpoints, along with how many were hit   at the current instruction, when relevant</li> </ul>"},{"location":"usage/debugger/#keyboard-shortcuts","title":"Keyboard shortcuts","text":"<p>On the home page, the following keyboard shortcuts are available:</p> Shortcut Mnemonic Description <code>q</code> quit exit the debugger <code>h</code> next pane cycle focus to the next pane <code>l</code> prev pane cycle focus to the previous pane <code>s</code> step advance the VM one cycle <code>n</code> step next advance the VM to the next instruction <code>c</code> continue advance the VM to the next breakpoint, else to completion <code>e</code> exit frame advance the VM until we exit the current call frame, a breakpoint is triggered, or execution terminates <code>d</code> delete delete an item (where applicable, e.g. the breakpoints pane) <code>:</code> command prompt bring up the command prompt (see below for details) <p>When various panes have focus, additional keyboard shortcuts are available, in any pane with a list of items, or multiple lines (e.g. source code), <code>j</code> and <code>k</code> (or the up and down arrows) will select the next item up and down, respectively. As more features are added, I will document their keyboard shortcuts below.</p>"},{"location":"usage/debugger/#commands","title":"Commands","text":"<p>From the home page, typing <code>:</code> will bring up the command prompt in the footer pane.</p> <p>You will know the prompt is active because the keyboard shortcuts normally shown there will no longer appear, and instead you will see the prompt, starting with <code>:</code>. It supports any of the following commands:</p> Command Aliases Action Description <code>quit</code> <code>q</code> quit exit the debugger <code>debug</code> show debug log display the internal debug log for the debugger itself <code>reload</code> reload program reloads the program from disk, and resets the UI (except breakpoints) <code>breakpoint</code> <code>break</code>, <code>b</code> create breakpoint see Breakpoints <code>read</code> <code>r</code> read memory inspect linear memory (see Reading Memory"},{"location":"usage/debugger/#breakpoints","title":"Breakpoints","text":"<p>One of the most common things you will want to do with the debugger is set and manage breakpoints. Using the command prompt, you can create breakpoints by typing <code>b</code> (or <code>break</code> or <code>breakpoint</code>), followed by a space, and then the desired breakpoint expression to do any of the following:</p> <ul> <li>Break at an instruction which corresponds to a source file (or file and line) whose name/path   matches a pattern</li> <li>Break at the first instruction which causes a call frame to be pushed for a procedure whose name   matches a pattern</li> <li>Break any time a specific opcode is executed</li> <li>Break at the next instruction</li> <li>Break after N cycles</li> <li>Break at CYCLE</li> </ul> <p>The syntax for each of these can be found below, in the same order (shown using <code>b</code> as the command):</p> Expression Description <code>b FILE[:LINE]</code> Break when an instruction with a source location in <code>FILE</code> (a glob pattern) and that occur on <code>LINE</code> (literal, if provided) are hit. <code>b in NAME</code> Break when the glob pattern <code>NAME</code> matches the fully-qualified procedure name containing the current instruction <code>b for OPCODE</code> Break when the an instruction with opcode <code>OPCODE</code> is exactly matched (including immediate values) <code>b next</code> Break on the next instruction <code>b after N</code> Break after <code>N</code> cycles <code>b at CYCLE</code> Break when the cycle count reaches <code>CYCLE</code>. If <code>CYCLE</code> has already occurred, this has no effect <p>When a breakpoint is hit, it will be highlighted, and the breakpoint window will display the number of hit breakpoints in the lower right.</p> <p>After a breakpoint is hit, it expires if it is one of the following types:</p> <ul> <li>Break after N</li> <li>Break at CYCLE</li> <li>Break next</li> </ul> <p>When a breakpoint expires, it is removed from the breakpoint list on the next cycle.</p>"},{"location":"usage/debugger/#reading-memory","title":"Reading memory","text":"<p>Another useful diagnostic task is examining the contents of linear memory, to verify that expected data has been written. You can do this via the command prompt, using <code>r</code> (or <code>read</code>), followed by a space, and then the desired memory address and options:</p> <p>The format for read expressions is <code>:r ADDR [OPTIONS..]</code>, where <code>ADDR</code> is a memory address in decimal or hexadecimal format (the latter requires the <code>0x</code> prefix). The <code>read</code> command supports the following for <code>OPTIONS</code>:</p> Option Alias Values Default Description <code>-mode MODE</code> <code>-m</code> <ul><li><code>words</code> (<code>word</code> ,<code>w</code>)</li><li><code>bytes</code> (<code>byte</code>, <code>b</code>) <code>words</code> Specify a memory addressing mode <code>-format FORMAT</code> <code>-f</code> <ul><li><code>decimal</code> (<code>d</code>)</li><li><code>hex</code> (<code>x</code>)</li><li><code>binary</code> (<code>bin</code>, <code>b</code>)</li></ul> <code>decimal</code> Specify the format used to print integral values <code>-count N</code> <code>-c</code> <code>1</code> Specify the number of units to read <code>-type TYPE</code> <code>-t</code> See Types <code>word</code> Specify the type of value to readThis also has the effect of modifying the default <code>-format</code> and unit size for <code>-count</code> <p>Any invalid combination of options, or invalid syntax, will display an error in the status bar.</p>"},{"location":"usage/debugger/#types","title":"Types","text":"Type Description <code>iN</code> A signed integer of <code>N</code> bits <code>uN</code> An unsigned integer of <code>N</code> bits <code>felt</code> A field element <code>word</code> A Miden word, i.e. an array of four field elements <code>ptr</code> or <code>pointer</code> A 32-bit memory address (implies <code>-format hex</code>)"},{"location":"usage/debugger/#roadmap","title":"Roadmap","text":"<p>The following are some features planned for the near future:</p> <ul> <li>Watchpoints, i.e. cause execution to break when a memory store touches a specific address</li> <li>Conditional breakpoints, i.e. only trigger a breakpoint when an expression attached to it   evaluates to true</li> <li>More DYIM-style breakpoints, i.e. when breaking on first hitting a match for a file or   procedure, we probably shouldn\u2019t continue to break for every instruction to which that   breakpoint technically applies. Instead, it would make sense to break and then temporarily   disable that breakpoint until something changes that would make breaking again useful.   This will rely on the ability to disable breakpoints, not delete them, which we don\u2019t yet   support.</li> <li>More robust type support in the <code>read</code> command</li> <li>Display procedure locals and their contents in a dedicated pane</li> </ul>"},{"location":"usage/midenc/","title":"Getting started with <code>midenc</code>","text":"<p>The <code>midenc</code> executable is the command-line interface for the compiler driver, as well as other helpful tools, such as the interactive debugger.</p> <p>While it is a lower-level tool compared to <code>cargo-miden</code>, just like the difference between <code>rustc</code> and <code>cargo</code>, it provides a lot of functionality for emitting diagnostic information, controlling the output of the compiler, and configuring the compilation pipeline. Most users will want to use <code>cargo-miden</code>, but understanding <code>midenc</code> is helpful for those times where you need to get your hands dirty.</p>"},{"location":"usage/midenc/#installation","title":"Installation","text":"<p>Warning</p> <p>Currently, <code>midenc</code> (and as a result, <code>cargo-miden</code>), requires the nightly Rust toolchain, so make sure you have it installed first:</p> <pre><code>rustup toolchain install nightly-2025-01-16\n</code></pre> <p>NOTE: You can also use the latest nightly, but the specific nightly shown here is known to work.</p> <p>To install the <code>midenc</code>, clone the compiler repo first:</p> <pre><code>git clone https://github.com/0xpolygonmiden/compiler\n</code></pre> <p>Then, run the following in your shell in the cloned repo folder:</p> <pre><code>cargo install --path midenc --locked\n</code></pre>"},{"location":"usage/midenc/#usage","title":"Usage","text":"<p>Once installed, you should be able to invoke the compiler, you should see output similar to this:</p> <pre><code>midenc help compile\nUsage: midenc compile [OPTIONS] [-- &lt;INPUTS&gt;...]\n\nArguments:\n  [INPUTS]...\n          Path(s) to the source file(s) to compile.\n\n          You may also use `-` as a file name to read a file from stdin.\n\nOptions:\n      --output-dir &lt;DIR&gt;\n          Write all compiler artifacts to DIR\n\n  -W &lt;LEVEL&gt;\n          Modify how warnings are treated by the compiler\n\n          [default: auto]\n\n          Possible values:\n          - none:  Disable all warnings\n          - auto:  Enable all warnings\n          - error: Promotes warnings to errors\n\n  -v, --verbose\n          When set, produces more verbose output during compilation\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>The actual help output covers quite a bit more than shown here, this is just for illustrative purposes.</p> <p>The <code>midenc</code> executable supports two primary functions at this time:</p> <ul> <li><code>midenc compile</code> to compile one of our supported input formats to Miden Assembly</li> <li><code>midenc debug</code> to run a Miden program attached to an interactive debugger</li> <li><code>midenc run</code> to run a Miden program non-interactively, equivalent to <code>miden run</code></li> </ul>"},{"location":"usage/midenc/#compilation","title":"Compilation","text":"<p>See the help output for <code>midenc compile</code> for detailed information on its options and their behavior. However, the following is an example of how one might use <code>midenc compile</code> in practice:</p> <pre><code>midenc compile --target rollup \\\n    --entrypoint 'foo::main' \\\n    -lextra \\\n    -L ./masm \\\n    --emit=hir=-,masp \\\n    -o out.masp \\\n    target/wasm32-wasip1/release/foo.wasm\n</code></pre> <p>In this scenario, we are in the root of a Rust crate, named <code>foo</code>, which we have compiled for the <code>wasm32-wasip1</code> target, which placed the resulting WebAssembly module in the <code>target/wasm32-wasip1/release</code> directory. This crate exports a function named <code>main</code>, which we want to use as the entrypoint of the program.</p> <p>Additionally, our Rust code links against some hand-written Miden Assembly code, namespaced under <code>extra</code>, which can be found in <code>./masm/extra</code>. We are telling <code>midenc</code> to link the <code>extra</code> library, and to add the <code>./masm</code> directory to the library search path.</p> <p>Lastly, we\u2019re configuring the output:</p> <ul> <li>We\u2019re using <code>--emit</code> to request <code>midenc</code> to dump Miden IR (<code>hir</code>) to stdout (specified via the <code>-</code> shorthand), in addition to the Miden package artifact (<code>masp</code>).</li> <li>We\u2019re telling <code>midenc</code> to write the compiled output to <code>out.masp</code> in the current directory, rather than the default path that would have been used (<code>target/miden/foo.masp</code>).</li> </ul>"},{"location":"usage/midenc/#debugging","title":"Debugging","text":"<p>See Debugging Programs for details on using <code>midenc debug</code> to debug Miden programs.</p>"},{"location":"usage/midenc/#next-steps","title":"Next steps","text":"<p>We have put together two useful guides to walk through more detail on compiling Rust to WebAssembly:</p> <ol> <li>To learn how to compile Rust to WebAssembly so that you can invoke <code>midenc compile</code> on the resulting Wasm module, see this guide.</li> <li>If you already have a WebAssembly module, or know how to produce one, and want to learn how to compile it to Miden Assembly, see this guide.</li> </ol> <p>You may also be interested in our basic account project template, as a starting point for your own Rust project.</p>"}]}